{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Equivariant Quantum Circuits for Combinatorial Optimization Problems"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-11-27T20:22:15.458705Z",
     "end_time": "2023-11-27T20:22:18.329118Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeray142\\AppData\\Local\\Temp\\ipykernel_16280\\4104614687.py:6: DeprecationWarning: The ``qiskit.opflow`` module is deprecated as of qiskit-terra 0.24.0. It will be removed no earlier than 3 months after the release date. For code migration guidelines, visit https://qisk.it/opflow_migration.\n",
      "  import qiskit.opflow\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# General imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import qiskit.opflow\n",
    "import typing_extensions\n",
    "from numpy import ndarray\n",
    "\n",
    "# Qiskit circuit imports\n",
    "from qiskit.circuit import ParameterVector, QuantumCircuit, QuantumRegister, Parameter, ParameterExpression\n",
    "\n",
    "# Qiskit imports\n",
    "from qiskit.utils import QuantumInstance, algorithm_globals\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "import qiskit_aer\n",
    "\n",
    "# Qiskit ML imports\n",
    "from qiskit_machine_learning.neural_networks import CircuitQNN, EstimatorQNN, SamplerQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import MSELoss, Module, Sequential\n",
    "from torch.optim import Adam\n",
    "\n",
    "BASE_PATH = 'data/'\n",
    "\n",
    "# Fix seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# For smooth plotting\n",
    "# REFERENCE: handson-ml3\n",
    "import matplotlib as mpl\n",
    "import matplotlib.animation as animation\n",
    "mpl.rc('animation', html='jshtml')\n",
    "\n",
    "def update_scene(num, frames, patch):\n",
    "    patch.set_data(frames[num])\n",
    "    return patch,\n",
    "\n",
    "def plot_animation(frames, repeat=False, interval=40):\n",
    "    fig = plt.figure()\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, update_scene, fargs=(frames, patch),\n",
    "        frames=len(frames), repeat=repeat, interval=interval\n",
    "    )\n",
    "    plt.close()\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'n_vars': 10,\n",
    "    'episodes': 5000,\n",
    "    'batch_size': 10,\n",
    "    'epsilon': 1,\n",
    "    'epsilon_decay': 0.99,\n",
    "    'epsilon_min': 0.01,\n",
    "    'gamma': 0.9,\n",
    "    'update_after': 10,\n",
    "    'update_target_after': 30,\n",
    "    'learning_rate_in': 0.00001,\n",
    "    'n_layers': 1,\n",
    "    'epsilon_schedule': 'fast',\n",
    "    'memory_length': 10000,\n",
    "    'num_instances': 100,\n",
    "    'data_path': BASE_PATH + 'tsp/tsp_10_train/tsp_10_reduced_train.pickle',\n",
    "    'repetitions': 1,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-27T20:26:13.467451Z",
     "end_time": "2023-11-27T20:26:13.482747Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Equivariant Quantum Circuit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def graph_encoding_circuit(edges, num_qubits, reps, params, insert_barriers = True) -> QuantumCircuit:\n",
    "    # Create a quantum circuit\n",
    "    circuit = QuantumCircuit(num_qubits)\n",
    "\n",
    "    # Apply Hadamard gates to all qubits\n",
    "    circuit.h(range(num_qubits))\n",
    "\n",
    "    for rep in range(reps):\n",
    "        edge_w = params[rep][-1]\n",
    "\n",
    "        # Edge encoding\n",
    "        for edge_i, edge in enumerate(edges):\n",
    "            circuit.cnot(edge[0], edge[1])\n",
    "\n",
    "            circuit.rz(edge_w[edge_i], edge[1])\n",
    "\n",
    "            circuit.cnot(edge[0], edge[1])\n",
    "\n",
    "        # This barrier is just to improve visualization, it can be removed\n",
    "        if insert_barriers: circuit.barrier()\n",
    "\n",
    "        # Vertex encoding\n",
    "        for q in range(num_qubits):\n",
    "            circuit.rx(params[rep][q], q)\n",
    "\n",
    "    return circuit"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-27T20:26:14.162514Z",
     "end_time": "2023-11-27T20:26:14.173816Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 929.397x264.88 with 1 Axes>",
      "image/png": "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\n"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_qubits = 4\n",
    "reps = 1\n",
    "edges = [(0, 1), (0, 2), (1, 3)] # Hardcoded edges for testing.\n",
    "n_edges = len(edges)\n",
    "\n",
    "data_symbols = []\n",
    "for layer in range(reps):\n",
    "    data = [Parameter(f'layer[{layer}]_v[{qubit}]') for qubit in range(n_qubits)]\n",
    "    data += [[Parameter(f'layer[{layer}]_e[{ew}]') for ew in range(n_edges)]]\n",
    "    data_symbols.append(data)\n",
    "\n",
    "qc = graph_encoding_circuit(edges, n_qubits, reps, data_symbols)\n",
    "qc.draw(\"mpl\", fold=50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-27T20:26:15.378381Z",
     "end_time": "2023-11-27T20:26:15.669065Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classical Layers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Equivariant Layer\n",
    "\n",
    "Not to be confused with the Equivariant Parametrized Quantum Circuit!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class EquivariantLayer(torch.nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_input_params : int,\n",
    "            n_vars : int,\n",
    "            n_edges : int,\n",
    "            circuit_depth : int,\n",
    "            params : list):\n",
    "        super(EquivariantLayer, self).__init__()\n",
    "\n",
    "        # Define weights for the Layer\n",
    "        self.num_input_params = num_input_params * circuit_depth\n",
    "        self.num_params = 2 * circuit_depth\n",
    "        self.circuit_depth = circuit_depth\n",
    "\n",
    "        param_init = torch.ones(1, self.num_params, dtype=torch.float32)\n",
    "        self.params = torch.nn.Parameter(param_init)\n",
    "\n",
    "        self.param_repeats = []\n",
    "        for layer in range(self.circuit_depth):\n",
    "            self.param_repeats.append(n_vars)\n",
    "            self.param_repeats.append(n_edges)\n",
    "\n",
    "        alphabetical_params = sorted(params)\n",
    "        self.indices = [params.index(a) for a in alphabetical_params]\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        repeated_params = self.params.repeat_interleave(torch.tensor(self.param_repeats))\n",
    "\n",
    "        repeat_inputs = inputs.repeat(self.circuit_depth, 1)\n",
    "\n",
    "        data_values = repeat_inputs * repeated_params\n",
    "        output = data_values[:, self.indices]\n",
    "\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-27T20:26:17.187586Z",
     "end_time": "2023-11-27T20:26:17.192584Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Post-processing layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class TrainableRescaling(torch.nn.Module):\n",
    "    def __init__(self, input_dim : int):\n",
    "        super(TrainableRescaling, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        In PyTorch does not have an argument controlling whether a Parameter is trainable or\n",
    "        not. If you want to freeze the parameter (making it non-trainable), you will need\n",
    "        to manually set requires_grad to False after the parameter is initialized.\n",
    "        \"\"\"\n",
    "        self.w = torch.nn.Parameter(torch.ones(1, input_dim), requires_grad=True)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return inputs * self.w.repeat(inputs.shape[0], 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-27T20:26:19.346974Z",
     "end_time": "2023-11-27T20:26:19.355973Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utils"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def graph_to_list(nodes : list, fully_connected_edges : list[tuple], edge_weights : dict,\n",
    "                  available_nodes : list[int], node_to_qubit_map : dict) -> list[float]:\n",
    "    vals = []\n",
    "    for node in nodes:\n",
    "        vals.append(int(node_to_qubit_map[node] in available_nodes) * np.pi)\n",
    "\n",
    "    for edge in fully_connected_edges:\n",
    "        vals.append(np.arctan(edge_weights[edge]))\n",
    "\n",
    "    return vals\n",
    "\n",
    "def compute_tour_length(nodes : list[tuple], tour : list[int]) -> float:\n",
    "    \"\"\"\n",
    "    Compute length of a tour, including return to start node.\n",
    "    (If start node is already added as last node in tour, 0 will be added to tour length.)\n",
    "    :param nodes: all nodes in the graph in form of (x, y) coordinates\n",
    "    :param tour: list of node indices denoting a (potentially partial) tour\n",
    "    :return: tour length\n",
    "    \"\"\"\n",
    "    tour_length = 0\n",
    "    for i in range(len(tour)):\n",
    "        if i < len(tour)-1:\n",
    "            tour_length += np.linalg.norm(np.asarray(nodes[tour[i]]) - np.asarray(nodes[tour[i+1]]))\n",
    "        else:\n",
    "            tour_length += np.linalg.norm(np.asarray(nodes[tour[-1]]) - np.asarray(nodes[tour[0]]))\n",
    "\n",
    "    return tour_length\n",
    "\n",
    "def cost(nodes : list[tuple], tour : list[int]) -> float:\n",
    "    return -compute_tour_length(nodes, tour)\n",
    "\n",
    "def compute_reward(nodes : list[tuple], old_state : list[int], state : list[int]):\n",
    "    return cost(nodes, state) - cost(nodes, old_state)\n",
    "\n",
    "def get_masks_for_actions(edge_weights, partial_tours):\n",
    "    batch_masks = []\n",
    "    for tour_ix, partial_tour in enumerate(partial_tours):\n",
    "        mask = []\n",
    "        for edge, weight in edge_weights[tour_ix].items():\n",
    "            if edge in partial_tour or (edge[1], edge[0]) in partial_tour:\n",
    "                mask.append(weight)\n",
    "            else:\n",
    "                mask.append(0)\n",
    "\n",
    "        batch_masks.append(mask)\n",
    "\n",
    "    return np.asarray(batch_masks)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-27T20:26:20.900423Z",
     "end_time": "2023-11-27T20:26:20.923421Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Q-Learning model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class QLearning:\n",
    "    def __init__(self, hyperparams : dict, path : str = BASE_PATH):\n",
    "        self.path = path\n",
    "\n",
    "        self.n_vars = hyperparams.get('n_vars')\n",
    "        self.episodes = hyperparams.get('episodes')\n",
    "        self.batch_size = hyperparams.get('batch_size')\n",
    "        self.gamma = hyperparams.get('gamma')\n",
    "        self.n_layers = hyperparams.get('n_layers')\n",
    "        self.update_after = hyperparams.get('update_after')\n",
    "        self.update_target_after = hyperparams.get('update_target_after')\n",
    "        self.memory_length = hyperparams.get('memory_length')\n",
    "        self.n_pred_layers = hyperparams.get('n_pred_layers', 1)\n",
    "\n",
    "        self.epsilon = hyperparams.get('epsilon')\n",
    "        self.epsilon_schedule = hyperparams.get('epsilon_schedule')\n",
    "        self.epsilon_min = hyperparams.get('epsilon_min')\n",
    "        self.epsilon_decay = hyperparams.get('epsilon_decay')\n",
    "\n",
    "        self.learning_rate = hyperparams.get('learning_rate', 0.01)\n",
    "        self.learning_rate_out = hyperparams.get('learning_rate_out', 0.01)\n",
    "        self.learning_rate_in = hyperparams.get('learning_rate_in', 0.01)\n",
    "\n",
    "        # We should add parameters to Adam\n",
    "        # self.optimizer = Adam({}, lr=self.learning_rate, amsgrad=True)\n",
    "        # self.optimizer_output = Adam({}, lr=self.learning_rate_out)\n",
    "        # self.optimizer_input = Adam({}, lr=self.learning_rate_in)\n",
    "\n",
    "        self.optimizers = []\n",
    "        self.w_idx = []\n",
    "\n",
    "        self.loss_fun = MSELoss()\n",
    "\n",
    "        self.memory = self.initialize_memory()\n",
    "\n",
    "        self.meta = self.generate_meta_data_dict()\n",
    "\n",
    "    def generate_meta_data_dict(self):\n",
    "        meta = {key: str(value) for key, value in self.__dict__.items() if\n",
    "                not key.startswith('__') and not callable(key)}\n",
    "\n",
    "        # del meta['optimizer']\n",
    "        # del meta['optimizer_output']\n",
    "        del meta['loss_fun']\n",
    "        del meta['memory']\n",
    "\n",
    "        return meta\n",
    "\n",
    "    def initialize_memory(self):\n",
    "        memory = deque(maxlen=self.memory_length)\n",
    "        return memory\n",
    "\n",
    "    def add_to_memory(self, state, action, reward, next_state, done):\n",
    "        transition = self.interaction(\n",
    "            state, action, reward, next_state, float(done))\n",
    "        self.memory.append(transition)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-27T20:26:22.992561Z",
     "end_time": "2023-11-27T20:26:23.008557Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1, running avg 1.9279332404327274, epsilon 0.99\n",
      "\tFinal tour: [0, 5, 1, 4, 9, 6, 7, 2, 8, 3, 0]\n",
      "Episode 2, running avg 1.7757560024189947, epsilon 0.9801\n",
      "\tFinal tour: [0, 8, 4, 1, 9, 2, 7, 5, 6, 3, 0]\n",
      "Episode 3, running avg 1.9010572419858143, epsilon 0.9702989999999999\n",
      "\tFinal tour: [0, 1, 3, 6, 9, 7, 8, 4, 2, 5, 0]\n",
      "Episode 4, running avg 1.8370166120482343, epsilon 0.96059601\n",
      "\tFinal tour: [0, 6, 4, 8, 3, 9, 7, 1, 5, 2, 0]\n",
      "Episode 5, running avg 1.8199479439976827, epsilon 0.9509900498999999\n",
      "\tFinal tour: [0, 3, 8, 1, 6, 5, 4, 9, 7, 2, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeray142\\AppData\\Local\\Temp\\ipykernel_16280\\4210566223.py:188: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  action = available_nodes[torch.argmax(torch.tensor(expectations)).item()]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6, running avg 1.8147890181245245, epsilon 0.9414801494009999\n",
      "\tFinal tour: [0, 8, 1, 5, 3, 2, 6, 7, 9, 4, 0]\n",
      "Episode 7, running avg 1.825171551030351, epsilon 0.9320653479069899\n",
      "\tFinal tour: [0, 1, 5, 7, 8, 2, 3, 9, 6, 4, 0]\n",
      "Episode 8, running avg 1.8863197293300762, epsilon 0.92274469442792\n",
      "\tFinal tour: [0, 3, 6, 9, 8, 5, 1, 2, 7, 4, 0]\n",
      "Episode 9, running avg 1.8647951350676246, epsilon 0.9135172474836407\n",
      "\tFinal tour: [0, 9, 8, 2, 5, 3, 7, 1, 6, 4, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeray142\\AppData\\Local\\Temp\\ipykernel_16280\\4210566223.py:220: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  future_rewards.append(torch.max(torch.tensor(exp_values)))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "QModel.forward() missing 1 required positional argument: 'observables'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [10]\u001B[0m, in \u001B[0;36m<cell line: 401>\u001B[1;34m()\u001B[0m\n\u001B[0;32m    401\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(hyperparams\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrepetitions\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m1\u001B[39m)):\n\u001B[0;32m    402\u001B[0m     tsp_multi \u001B[38;5;241m=\u001B[39m QLearningTsp(\n\u001B[0;32m    403\u001B[0m         hyperparams\u001B[38;5;241m=\u001B[39mhyperparams,\n\u001B[0;32m    404\u001B[0m         path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/save_path/\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    405\u001B[0m     )\n\u001B[1;32m--> 407\u001B[0m     \u001B[43mtsp_multi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mperform_episodes\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    408\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_instances\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhyperparams\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnum_instances\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    409\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [10]\u001B[0m, in \u001B[0;36mQLearningTsp.perform_episodes\u001B[1;34m(self, num_instances)\u001B[0m\n\u001B[0;32m    361\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmemory) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_size:\n\u001B[0;32m    362\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m episode \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdate_after \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 363\u001B[0m         loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    364\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    365\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpisode \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepisode\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, loss \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, running avg \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrunning_avg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, epsilon \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepsilon\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    366\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124mFinal tour: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtour\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Input \u001B[1;32mIn [10]\u001B[0m, in \u001B[0;36mQLearningTsp.train_step\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    225\u001B[0m target_q_values \u001B[38;5;241m=\u001B[39m rewards \u001B[38;5;241m+\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgamma \u001B[38;5;241m*\u001B[39m torch\u001B[38;5;241m.\u001B[39mstack(future_rewards) \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m-\u001B[39m done))\n\u001B[0;32m    227\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m--> 229\u001B[0m exp_values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    230\u001B[0m exp_val_masks \u001B[38;5;241m=\u001B[39m get_masks_for_actions(edge_weights, partial_tours)\n\u001B[0;32m    231\u001B[0m q_values_masked \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msum(exp_values\u001B[38;5;241m.\u001B[39mdetach() \u001B[38;5;241m*\u001B[39m exp_val_masks, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "\u001B[1;31mTypeError\u001B[0m: QModel.forward() missing 1 required positional argument: 'observables'"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from collections import namedtuple\n",
    "\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "class QModel(Module):\n",
    "    def __init__(self, n_input_params : int, n_vars : int, num_edges_in_graph : int, n_layers : int,\n",
    "                 flattened_data_symbols : list, circuit : QuantumCircuit):\n",
    "        super(QModel, self).__init__()\n",
    "\n",
    "        self.encoding_layer = EquivariantLayer(num_input_params=n_input_params, n_vars=n_vars, n_edges=num_edges_in_graph,\n",
    "                                               circuit_depth=n_layers, params=flattened_data_symbols)\n",
    "\n",
    "        self.circuit = circuit\n",
    "        #self.output_extension_layer = Sequential(\n",
    "        #    TrainableRescaling(n_readout_op)\n",
    "        #)\n",
    "\n",
    "    def forward(self, input_data, observables):\n",
    "        encoding_output = self.encoding_layer(input_data)\n",
    "\n",
    "        qnn = EstimatorQNN(\n",
    "            circuit=self.circuit,\n",
    "            input_params=self.circuit.parameters,\n",
    "            observables=observables\n",
    "        )\n",
    "        qnn = TorchConnector(qnn)\n",
    "        expectation_values = qnn(encoding_output)\n",
    "\n",
    "        # output = self.output_extension_layer(expectation_values)\n",
    "        return expectation_values\n",
    "\n",
    "class QLearningTsp(QLearning):\n",
    "    def __init__(self,\n",
    "                 hyperparams : dict,\n",
    "                 path :str =BASE_PATH):\n",
    "\n",
    "        super(QLearningTsp, self).__init__(hyperparams, path)\n",
    "\n",
    "        self.fully_connected_qubits = list(combinations(list(range(self.n_vars)), 2))\n",
    "        self.is_multi_instance = hyperparams.get('is_multi_instance')\n",
    "        self.interaction = namedtuple(typename='interaction', field_names=('state', 'action', 'reward', 'next_state', 'done', 'partial_tour', 'edge_weights'))\n",
    "        self.model = self.generate_eqc_model()\n",
    "\n",
    "        self.optimizer = Adam(self.model.parameters(), lr=self.learning_rate_in)\n",
    "\n",
    "        self.data_path = hyperparams.get('data_path')\n",
    "\n",
    "    def generate_eqc_model(self):\n",
    "        num_edges_in_graph = len(self.fully_connected_qubits)\n",
    "        n_input_params = self.n_vars + num_edges_in_graph\n",
    "\n",
    "        data_symbols = []\n",
    "        for layer in range(self.n_layers):\n",
    "            data = [Parameter(f'layer[{layer}]_v[{qubit}]') for qubit in range(self.n_vars)]\n",
    "            data += [[Parameter(f'layer[{layer}]_e[{ew}]') for ew in range(num_edges_in_graph)]]\n",
    "            data_symbols.append(data)\n",
    "\n",
    "        circuit = graph_encoding_circuit(self.fully_connected_qubits, self.n_vars, self.n_layers, data_symbols)\n",
    "\n",
    "        flattened_data_symbols = []\n",
    "        for layer in data_symbols:\n",
    "            for item in layer:\n",
    "                if type(item) == list:\n",
    "                    for symbol in item:\n",
    "                        flattened_data_symbols.append(str(symbol))\n",
    "                else:\n",
    "                    flattened_data_symbols.append(str(item))\n",
    "\n",
    "        model = QModel(n_input_params=n_input_params, n_vars=self.n_vars, num_edges_in_graph=num_edges_in_graph, n_layers=self.n_layers,\n",
    "                       flattened_data_symbols=flattened_data_symbols, circuit=circuit)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def q_vals_from_expectation(self, partial_tours : list,\n",
    "                                edge_weights : list, expectations) -> ndarray:\n",
    "        expectations = expectations.detach().numpy()\n",
    "        indexed_expectations = []\n",
    "        for exps in expectations:\n",
    "            batch_ix_exp = {}\n",
    "            for edge, exp_val in zip(self.fully_connected_qubits, exps):\n",
    "                batch_ix_exp[edge] = exp_val\n",
    "            indexed_expectations.append(batch_ix_exp)\n",
    "\n",
    "        batch_q_vals = []\n",
    "        for tour_ix, partial_tour in enumerate(partial_tours):\n",
    "            q_vals = []\n",
    "            for i in range(self.n_vars):\n",
    "                node_in_tour = False\n",
    "                for edge in partial_tour:\n",
    "                    if i in edge:\n",
    "                        node_in_tour = True\n",
    "\n",
    "                if not node_in_tour:\n",
    "                    next_edge = None\n",
    "                    if partial_tour:\n",
    "                        next_edge = (partial_tour[-1][1], i)\n",
    "                    else:\n",
    "                        if i > 0:\n",
    "                            next_edge = (0, i)\n",
    "\n",
    "                    if next_edge is not None:\n",
    "                        try:\n",
    "                            q_val = edge_weights[tour_ix][next_edge] * indexed_expectations[tour_ix][next_edge]\n",
    "                        except KeyError:\n",
    "                            q_val = edge_weights[tour_ix][\n",
    "                                (next_edge[1], next_edge[0])] * indexed_expectations[tour_ix][\n",
    "                                        (next_edge[1], next_edge[0])]\n",
    "                    else:\n",
    "                        q_val = -10000\n",
    "                else:\n",
    "                    q_val = -10000\n",
    "                q_vals.append(q_val)\n",
    "\n",
    "            batch_q_vals.append(q_vals)\n",
    "\n",
    "        return np.asarray(batch_q_vals)\n",
    "\n",
    "    def get_observables(self, edge_weights: dict | list[dict], partial_tours:  list[int] | list[list[int]]) -> tuple[list[SparsePauliOp], list[int]] | list[tuple[list[SparsePauliOp], list[int]]]:\n",
    "        if not isinstance(edge_weights, list):\n",
    "            edge_weights = [edge_weights]\n",
    "\n",
    "        if not isinstance(partial_tours[0], list):\n",
    "            partial_tours = [partial_tours]\n",
    "\n",
    "        observables_batch = []\n",
    "        available_nodes_batch = []\n",
    "\n",
    "        for i, partial_tour in enumerate(partial_tours):\n",
    "            observables = []\n",
    "            available_nodes = []\n",
    "            last_edge = partial_tour[-1]\n",
    "            last_node = last_edge[1]\n",
    "\n",
    "            edge_weight_batch = edge_weights[i] if isinstance(edge_weights[i], list) else [edge_weights[i]]\n",
    "\n",
    "            for edge_weight in edge_weight_batch:\n",
    "                for edge, weight in edge_weight.items():\n",
    "                    if edge[0] == last_node or edge[1] == last_node:\n",
    "                        if edge[0] == last_node and len([tup for tup in partial_tour if tup[0] == edge[1]]) >= 1:\n",
    "                            continue\n",
    "                        elif edge[1] == last_node and len([tup for tup in partial_tour if tup[0] == edge[0]]) >= 1:\n",
    "                            continue\n",
    "\n",
    "                        if edge[0] == last_node:\n",
    "                            available_nodes.append(edge[1])\n",
    "                        else:\n",
    "                            available_nodes.append(edge[0])\n",
    "\n",
    "                        observable = SparsePauliOp.from_sparse_list(\n",
    "                            [(\"ZZ\", [edge[0], edge[1]], weight)],\n",
    "                            num_qubits=self.n_vars\n",
    "                        )\n",
    "                        observables.append(observable)\n",
    "\n",
    "            if observables == []:\n",
    "                observable = SparsePauliOp.from_sparse_list(\n",
    "                    [(\"I\", [0], 0)],\n",
    "                    num_qubits=self.n_vars\n",
    "                )\n",
    "                observables.append(observable)\n",
    "                available_nodes.append(0)\n",
    "\n",
    "            observables_batch.append(observables)\n",
    "            available_nodes_batch.append(available_nodes)\n",
    "\n",
    "        if len(partial_tours) == 1:\n",
    "            return observables_batch[0], available_nodes_batch[0]\n",
    "        else:\n",
    "            return observables_batch, available_nodes_batch\n",
    "\n",
    "    def get_action(self, state_list : list[float], available_nodes : list,\n",
    "                   partial_tour : list[int], edge_weights : dict):\n",
    "\n",
    "        if np.random.uniform() < self.epsilon:\n",
    "            action = random.choice(available_nodes)\n",
    "        else:\n",
    "            state_tensor = torch.tensor(state_list).unsqueeze(0)\n",
    "\n",
    "            observables, available_nodes = self.get_observables(\n",
    "                edge_weights=edge_weights,\n",
    "                partial_tours=partial_tour\n",
    "            )\n",
    "            expectations = self.model(state_tensor, observables)\n",
    "\n",
    "            # q_vals = self.q_vals_from_expectation([partial_tour], [edge_weights], expectations)[0]\n",
    "            action = available_nodes[torch.argmax(torch.tensor(expectations)).item()]\n",
    "\n",
    "        return action\n",
    "\n",
    "    def train_step(self):\n",
    "        training_batch = random.choices(self.memory, k=self.batch_size)\n",
    "        training_batch = self.interaction(*zip(*training_batch))\n",
    "\n",
    "        states = [x for x in training_batch.state]\n",
    "        rewards = np.asarray([x for x in training_batch.reward], dtype=np.float32)\n",
    "        next_states = [x for x in training_batch.next_state]\n",
    "        done = np.asarray([x for x in training_batch.done])\n",
    "        partial_tours = [x for x in training_batch.partial_tour]\n",
    "        edge_weights = [x for x in training_batch.edge_weights]\n",
    "\n",
    "        states = torch.tensor(states)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32)\n",
    "        next_states = torch.tensor(next_states)\n",
    "        done = torch.tensor(done, dtype=torch.float64)\n",
    "\n",
    "        observables_batched, available_nodes_batched = self.get_observables(\n",
    "            edge_weights=edge_weights,\n",
    "            partial_tours=partial_tours\n",
    "        )\n",
    "\n",
    "        exp_values_future = []\n",
    "        for i, observables in enumerate(observables_batched):\n",
    "            exp_values_future.append(self.model(next_states[i], observables))\n",
    "        \n",
    "        # TODO: Use available_nodes to get the future_rewards.\n",
    "        future_rewards = []\n",
    "        for exp_values in exp_values_future:\n",
    "            future_rewards.append(torch.max(torch.tensor(exp_values)))\n",
    "\n",
    "        #future_rewards = torch.tensor(self.q_vals_from_expectation(\n",
    "        #    partial_tours, edge_weights, exp_values_future), dtype=torch.float64)\n",
    "\n",
    "        target_q_values = rewards + (self.gamma * torch.stack(future_rewards) * (1.0 - done))\n",
    "\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        # TODO: Precalculate the observables and use them with masks.\n",
    "        exp_values = self.model(states)\n",
    "        exp_val_masks = get_masks_for_actions(edge_weights, partial_tours)\n",
    "        q_values_masked = torch.sum(exp_values.detach() * exp_val_masks, dim=1)\n",
    "        loss = self.loss_fun(target_q_values, q_values_masked)\n",
    "\n",
    "        # Backward pass\n",
    "        # loss.backward()\n",
    "\n",
    "        grads = [param.grad for param in self.model.parameters()]\n",
    "\n",
    "        if len(self.optimizers) == 1:\n",
    "            # Compute the gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            self.optimizers[0].step()\n",
    "        else:\n",
    "            for optimizer, w in zip(self.optimizers, self.w_idx):\n",
    "                optimizer.zero_grad() # Clear the gradient buffer\n",
    "                loss.backward() # Compute gradients for each variable\n",
    "\n",
    "                # Manually set gradients for specific parameters and update weights\n",
    "                for ind, param in enumerate(self.model.parameters()):\n",
    "                    if ind == w:\n",
    "                        param.grad = grads[w] # grads[w] is assumed to be already known\n",
    "                optimizer.step()\n",
    "\n",
    "        # After updating weights, you may want to set the gradients to zero for the next iteration\n",
    "        for optimizer in self.optimizers:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        return loss.numpy()\n",
    "\n",
    "    def perform_episodes(self, num_instances : int) -> None:\n",
    "        self.meta['num_instances'] = num_instances\n",
    "        self.meta['best_tour_length'] = 100000\n",
    "        self.meta['best_tour'] = []\n",
    "        self.meta['best_tour_ix'] = 0\n",
    "        self.meta['env_solved'] = False\n",
    "\n",
    "        with open(self.data_path, 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "\n",
    "        if self.is_multi_instance:\n",
    "            x_train = data['x_train'][:num_instances]\n",
    "            y_train = data['y_train'][:num_instances]\n",
    "        else:\n",
    "            x_train = data['x_train']\n",
    "            y_train = data['y_train']\n",
    "\n",
    "        tour_length_history = []\n",
    "        optimal_tour_length_history = []\n",
    "        ratio_history = []\n",
    "        running_avgs = []\n",
    "        running_avg = 0\n",
    "\n",
    "        for episode in range(self.episodes):\n",
    "            instance_number = random.randint(0, num_instances - 1)\n",
    "            tsp_graph_nodes = x_train[instance_number]\n",
    "            optimal_tour_length = compute_tour_length(\n",
    "                tsp_graph_nodes, [int(x - 1) for x in y_train[instance_number][:-1]])\n",
    "            node_to_qubit_map = {}\n",
    "            for i, node in enumerate(tsp_graph_nodes):\n",
    "                node_to_qubit_map[node] = i\n",
    "\n",
    "            fully_connected_edges = []\n",
    "            edge_weights = {}\n",
    "            edge_weights_ix = {}\n",
    "            for edge in self.fully_connected_qubits:\n",
    "                fully_connected_edges.append((tsp_graph_nodes[edge[0]], tsp_graph_nodes[edge[1]]))\n",
    "                edge_distance = np.linalg.norm(\n",
    "                    np.asarray(tsp_graph_nodes[edge[0]]) - np.asarray(tsp_graph_nodes[edge[1]]))\n",
    "                edge_weights[(tsp_graph_nodes[edge[0]], tsp_graph_nodes[edge[1]])] = edge_distance\n",
    "                edge_weights_ix[edge] = edge_distance\n",
    "\n",
    "            tour = [0]  # Without loss of generality we always start at city 0\n",
    "            tour_edges = []\n",
    "            step_rewards = []\n",
    "            available_nodes = list(range(1, self.n_vars))\n",
    "\n",
    "            for i in range(self.n_vars):\n",
    "                prev_tour = copy.deepcopy(tour)\n",
    "                state_list = graph_to_list(\n",
    "                    tsp_graph_nodes, fully_connected_edges, edge_weights,\n",
    "                    available_nodes, node_to_qubit_map)\n",
    "\n",
    "                next_node = self.get_action(state_list, available_nodes, tour_edges, edge_weights_ix)\n",
    "                tour_edges.append((tour[-1], next_node))\n",
    "                new_tour_edges = copy.deepcopy(tour_edges)\n",
    "                tour.append(next_node)\n",
    "\n",
    "                remove_node_ix = available_nodes.index(next_node)\n",
    "                del available_nodes[remove_node_ix]\n",
    "\n",
    "                if len(tour) > 1:\n",
    "                    reward = compute_reward(tsp_graph_nodes, prev_tour, tour)\n",
    "                    step_rewards.append(reward)\n",
    "\n",
    "                    done = 0 if len(available_nodes) > 1 else 1\n",
    "                    transition = (state_list, next_node, reward, graph_to_list(\n",
    "                        tsp_graph_nodes, fully_connected_edges, edge_weights,\n",
    "                        available_nodes, node_to_qubit_map), done, new_tour_edges, edge_weights_ix)\n",
    "                    self.memory.append(transition)\n",
    "\n",
    "                if len(available_nodes) == 1:\n",
    "                    prev_tour = copy.deepcopy(tour)\n",
    "\n",
    "                    tour_edges.append((tour[-1], available_nodes[0]))\n",
    "                    tour_edges.append((available_nodes[0], tour[0]))\n",
    "                    new_tour_edges = copy.deepcopy(tour_edges)\n",
    "\n",
    "                    tour.append(available_nodes[0])\n",
    "                    tour.append(tour[0])\n",
    "\n",
    "                    reward = compute_reward(tsp_graph_nodes, prev_tour, tour)\n",
    "                    step_rewards.append(reward)\n",
    "\n",
    "                    transition = (state_list, next_node, reward, graph_to_list(\n",
    "                        tsp_graph_nodes, fully_connected_edges, edge_weights,\n",
    "                        available_nodes, node_to_qubit_map), 1, new_tour_edges, edge_weights_ix)\n",
    "                    self.memory.append(transition)\n",
    "                    break\n",
    "\n",
    "            tour_length = compute_tour_length(tsp_graph_nodes, tour)\n",
    "            tour_length_history.append(tour_length)\n",
    "            optimal_tour_length_history.append(optimal_tour_length)\n",
    "\n",
    "            if tour_length < self.meta.get('best_tour_length'):\n",
    "                self.meta['best_tour_length'] = tour_length\n",
    "                self.meta['best_tour'] = tour\n",
    "                self.meta['best_tour_ix'] = instance_number\n",
    "\n",
    "            if len(self.memory) >= self.batch_size:\n",
    "                if episode % self.update_after == 0:\n",
    "                    loss = self.train_step()\n",
    "                    print(\n",
    "                        f\"Episode {episode}, loss {loss}, running avg {running_avg}, epsilon {self.epsilon}\")\n",
    "                    print(f\"\\tFinal tour: {tour}\")\n",
    "                else:\n",
    "                    print(\n",
    "                            f\"Episode {episode}, running avg {running_avg}, epsilon {self.epsilon}\")\n",
    "                    print(f\"\\tFinal tour: {tour}\")\n",
    "\n",
    "                # TODO: Set weights for the target model.\n",
    "                # if episode % self.update_target_after == 0:\n",
    "                    # self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "            if self.epsilon_schedule == 'fast':\n",
    "                self.epsilon = max(self.epsilon_min, self.epsilon_decay * self.epsilon)\n",
    "\n",
    "            ratio_history.append(tour_length_history[-1] / optimal_tour_length)\n",
    "\n",
    "            if len(ratio_history) >= 100:\n",
    "                running_avg = np.mean(ratio_history[-100:])\n",
    "            else:\n",
    "                running_avg = np.mean(ratio_history)\n",
    "\n",
    "            running_avgs.append(running_avg)\n",
    "\n",
    "            if len(ratio_history) >= 100 and running_avg <= 1.05:\n",
    "                print(f\"Environment solved in {episode+1} episodes!\")\n",
    "                self.meta['env_solved'] = True\n",
    "                break\n",
    "\n",
    "        # This is just for visualization purposes.\n",
    "        plt.plot(running_avgs)\n",
    "        plt.ylabel(\"Ratio to optimal tour length\")\n",
    "        plt.xlabel(\"Episode\")\n",
    "        plt.title(\"Running average over past 100 episodes\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "for i in range(hyperparams.get('repetitions', 1)):\n",
    "    tsp_multi = QLearningTsp(\n",
    "        hyperparams=hyperparams,\n",
    "        path='/save_path/',\n",
    "    )\n",
    "\n",
    "    tsp_multi.perform_episodes(\n",
    "        num_instances=hyperparams.get('num_instances')\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-27T20:26:26.336754Z",
     "end_time": "2023-11-27T20:26:39.419003Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
