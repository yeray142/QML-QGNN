{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Equivariant Quantum Circuits for Combinatorial Optimization Problems"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:09:04.695470400Z",
     "start_time": "2023-11-30T10:09:01.623144600Z"
    }
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import random\n",
    "import pickle\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque, namedtuple\n",
    "from itertools import combinations\n",
    "from utils.utils import graph_to_list, compute_tour_length, compute_reward, get_masks_for_actions\n",
    "\n",
    "# Qiskit algorithms imports\n",
    "from qiskit_algorithms.utils import algorithm_globals\n",
    "\n",
    "# Qiskit imports\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit.circuit import QuantumCircuit, Parameter\n",
    "\n",
    "# Qiskit ML imports\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "from torch.nn import MSELoss, Module\n",
    "from torch.optim import Adam\n",
    "\n",
    "BASE_PATH = '../data/'\n",
    "\n",
    "# Fix seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "algorithm_globals.random_seed = random\n",
    "\n",
    "# For smooth plotting\n",
    "# REFERENCE: handson-ml3\n",
    "import matplotlib as mpl\n",
    "import matplotlib.animation as animation\n",
    "mpl.rc('animation', html='jshtml')\n",
    "\n",
    "def update_scene(num, frames, patch):\n",
    "    patch.set_data(frames[num])\n",
    "    return patch,\n",
    "\n",
    "def plot_animation(frames, repeat=False, interval=40):\n",
    "    fig = plt.figure()\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, update_scene, fargs=(frames, patch),\n",
    "        frames=len(frames), repeat=repeat, interval=interval\n",
    "    )\n",
    "    plt.close()\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'n_vars': 10,\n",
    "    'episodes': 5000,\n",
    "    'batch_size': 10,\n",
    "    'epsilon': 1,\n",
    "    'epsilon_decay': 0.99,\n",
    "    'epsilon_min': 0.01,\n",
    "    'gamma': 0.9,\n",
    "    'update_after': 10,\n",
    "    'update_target_after': 30,\n",
    "    'learning_rate_in': 0.00001,\n",
    "    'n_layers': 1,\n",
    "    'epsilon_schedule': 'fast',\n",
    "    'memory_length': 10000,\n",
    "    'num_instances': 100,\n",
    "    'data_path': BASE_PATH + 'tsp/tsp_10_train/tsp_10_reduced_train.pickle',\n",
    "    'repetitions': 1,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:09:04.700505200Z",
     "start_time": "2023-11-30T10:09:04.696487500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Equivariant Quantum Circuit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def graph_encoding_circuit(edges, num_qubits, reps, params, insert_barriers = True) -> QuantumCircuit:\n",
    "    # Create a quantum circuit\n",
    "    circuit = QuantumCircuit(num_qubits)\n",
    "\n",
    "    # Apply Hadamard gates to all qubits\n",
    "    circuit.h(range(num_qubits))\n",
    "\n",
    "    for rep in range(reps):\n",
    "        edge_w = params[rep][-1]\n",
    "\n",
    "        # Edge encoding\n",
    "        for edge_i, edge in enumerate(edges):\n",
    "            circuit.cx(edge[0], edge[1])\n",
    "\n",
    "            circuit.rz(edge_w[edge_i], edge[1])\n",
    "\n",
    "            circuit.cx(edge[0], edge[1])\n",
    "\n",
    "        # This barrier is just to improve visualization, it can be removed\n",
    "        if insert_barriers: circuit.barrier()\n",
    "\n",
    "        # Vertex encoding\n",
    "        for q in range(num_qubits):\n",
    "            circuit.rx(params[rep][q], q)\n",
    "\n",
    "    return circuit"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:09:04.704787300Z",
     "start_time": "2023-11-30T10:09:04.702498300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1290.83x367.889 with 1 Axes>",
      "image/png": "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"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_qubits = 4\n",
    "reps = 1\n",
    "edges = [(0, 1), (0, 2), (1, 3)] # Hardcoded edges for testing.\n",
    "n_edges = len(edges)\n",
    "\n",
    "data_symbols = []\n",
    "for layer in range(reps):\n",
    "    data = [Parameter(f'layer[{layer}]_v[{qubit}]') for qubit in range(n_qubits)]\n",
    "    data += [[Parameter(f'layer[{layer}]_e[{ew}]') for ew in range(n_edges)]]\n",
    "    data_symbols.append(data)\n",
    "\n",
    "qc = graph_encoding_circuit(edges, n_qubits, reps, data_symbols)\n",
    "qc.draw(output='mpl', fold=50, style=\"iqp\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:09:05.088891Z",
     "start_time": "2023-11-30T10:09:04.707839400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classical Layers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Equivariant Layer\n",
    "\n",
    "Not to be confused with the Equivariant Parametrized Quantum Circuit!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class EquivariantLayer(Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_input_params : int,\n",
    "            n_vars : int,\n",
    "            n_edges : int,\n",
    "            circuit_depth : int,\n",
    "            params : list):\n",
    "        super(EquivariantLayer, self).__init__()\n",
    "\n",
    "        # Define weights for the Layer\n",
    "        self.num_input_params = num_input_params * circuit_depth\n",
    "        self.num_params = 2 * circuit_depth\n",
    "        self.circuit_depth = circuit_depth\n",
    "\n",
    "        param_init = torch.ones(1, self.num_params, dtype=torch.float32)\n",
    "        self.params = torch.nn.Parameter(param_init)\n",
    "\n",
    "        self.param_repeats = []\n",
    "        for layer in range(self.circuit_depth):\n",
    "            self.param_repeats.append(n_vars)\n",
    "            self.param_repeats.append(n_edges)\n",
    "\n",
    "        alphabetical_params = sorted(params)\n",
    "        self.indices = [params.index(a) for a in alphabetical_params]\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        repeated_params = self.params.repeat_interleave(torch.tensor(self.param_repeats))\n",
    "\n",
    "        repeat_inputs = inputs.repeat(self.circuit_depth, 1)\n",
    "\n",
    "        data_values = repeat_inputs * repeated_params\n",
    "        output = data_values[:, self.indices]\n",
    "\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:09:05.096131200Z",
     "start_time": "2023-11-30T10:09:05.089887Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Q-Learning model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class QLearning:\n",
    "    def __init__(self, hyperparams : dict, path : str = BASE_PATH):\n",
    "        self.path = path\n",
    "\n",
    "        self.n_vars = hyperparams.get('n_vars')\n",
    "        self.episodes = hyperparams.get('episodes')\n",
    "        self.batch_size = hyperparams.get('batch_size')\n",
    "        self.gamma = hyperparams.get('gamma')\n",
    "        self.n_layers = hyperparams.get('n_layers')\n",
    "        self.update_after = hyperparams.get('update_after')\n",
    "        self.update_target_after = hyperparams.get('update_target_after')\n",
    "        self.memory_length = hyperparams.get('memory_length')\n",
    "        self.n_pred_layers = hyperparams.get('n_pred_layers', 1)\n",
    "\n",
    "        self.epsilon = hyperparams.get('epsilon')\n",
    "        self.epsilon_schedule = hyperparams.get('epsilon_schedule')\n",
    "        self.epsilon_min = hyperparams.get('epsilon_min')\n",
    "        self.epsilon_decay = hyperparams.get('epsilon_decay')\n",
    "\n",
    "        self.learning_rate = hyperparams.get('learning_rate', 0.01)\n",
    "        self.learning_rate_out = hyperparams.get('learning_rate_out', 0.01)\n",
    "        self.learning_rate_in = hyperparams.get('learning_rate_in', 0.01)\n",
    "\n",
    "        self.optimizers = []\n",
    "        self.w_idx = []\n",
    "\n",
    "        self.loss_fun = MSELoss()\n",
    "\n",
    "        self.memory = self.initialize_memory()\n",
    "\n",
    "        self.meta = self.generate_meta_data_dict()\n",
    "\n",
    "    def generate_meta_data_dict(self):\n",
    "        meta = {key: str(value) for key, value in self.__dict__.items() if\n",
    "                not key.startswith('__') and not callable(key)}\n",
    "\n",
    "        del meta['loss_fun']\n",
    "        del meta['memory']\n",
    "\n",
    "        return meta\n",
    "\n",
    "    def initialize_memory(self):\n",
    "        memory = deque(maxlen=self.memory_length)\n",
    "        return memory\n",
    "\n",
    "    def add_to_memory(self, state, action, reward, next_state, done):\n",
    "        transition = self.interaction(\n",
    "            state, action, reward, next_state, float(done))\n",
    "        self.memory.append(transition)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:09:05.103153100Z",
     "start_time": "2023-11-30T10:09:05.096131200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1, running avg 1.6915864266432532, epsilon 0.99\n",
      "\tFinal tour: [0, 5, 2, 1, 9, 7, 3, 8, 4, 6, 0]\n",
      "Episode 2, running avg 1.9213827746347887, epsilon 0.9801\n",
      "\tFinal tour: [0, 7, 8, 9, 1, 6, 5, 4, 2, 3, 0]\n",
      "Episode 3, running avg 2.066808229819473, epsilon 0.9702989999999999\n",
      "\tFinal tour: [0, 5, 2, 7, 4, 6, 1, 9, 8, 3, 0]\n",
      "Episode 4, running avg 2.014835255112027, epsilon 0.96059601\n",
      "\tFinal tour: [0, 1, 9, 4, 2, 7, 8, 5, 6, 3, 0]\n",
      "Episode 5, running avg 1.909800201699063, epsilon 0.9509900498999999\n",
      "\tFinal tour: [0, 2, 1, 9, 7, 6, 3, 8, 5, 4, 0]\n",
      "Episode 6, running avg 1.9382993671841617, epsilon 0.9414801494009999\n",
      "\tFinal tour: [0, 1, 6, 5, 7, 2, 3, 9, 8, 4, 0]\n",
      "Episode 7, running avg 1.935615147196349, epsilon 0.9320653479069899\n",
      "\tFinal tour: [0, 5, 3, 9, 7, 6, 2, 4, 1, 8, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_15812\\3188424776.py:142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  action = available_nodes[torch.argmax(torch.tensor(expectations)).item()]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 8, running avg 1.9156170754681225, epsilon 0.92274469442792\n",
      "\tFinal tour: [0, 5, 6, 7, 1, 4, 3, 9, 8, 2, 0]\n",
      "Episode 9, running avg 1.9188364286701436, epsilon 0.9135172474836407\n",
      "\tFinal tour: [0, 9, 7, 2, 5, 8, 1, 4, 6, 3, 0]\n",
      "Episode 10, loss None, running avg 1.8521929991090658, epsilon 0.9043820750088043\n",
      "\tFinal tour: [0, 2, 4, 9, 6, 7, 8, 3, 5, 1, 0]\n",
      "Episode 11, running avg 1.847652500106598, epsilon 0.8953382542587163\n",
      "\tFinal tour: [0, 4, 3, 2, 8, 9, 5, 1, 6, 7, 0]\n",
      "Episode 12, running avg 1.8535898183868589, epsilon 0.8863848717161291\n",
      "\tFinal tour: [0, 7, 4, 6, 8, 9, 1, 2, 5, 3, 0]\n",
      "Episode 13, running avg 1.8374170685605418, epsilon 0.8775210229989678\n",
      "\tFinal tour: [0, 3, 2, 6, 8, 1, 7, 4, 9, 5, 0]\n",
      "Episode 14, running avg 1.8254283136650575, epsilon 0.8687458127689781\n",
      "\tFinal tour: [0, 9, 5, 3, 1, 8, 7, 2, 4, 6, 0]\n",
      "Episode 15, running avg 1.8457649936476659, epsilon 0.8600583546412883\n",
      "\tFinal tour: [0, 3, 8, 6, 5, 4, 9, 1, 7, 2, 0]\n",
      "Episode 16, running avg 1.878773601581401, epsilon 0.8514577710948754\n",
      "\tFinal tour: [0, 1, 9, 5, 3, 4, 7, 8, 2, 6, 0]\n",
      "Episode 17, running avg 1.874902467074196, epsilon 0.8429431933839266\n",
      "\tFinal tour: [0, 9, 8, 4, 2, 3, 5, 6, 1, 7, 0]\n",
      "Episode 18, running avg 1.87475246120478, epsilon 0.8345137614500874\n",
      "\tFinal tour: [0, 4, 8, 3, 5, 9, 6, 1, 2, 7, 0]\n",
      "Episode 19, running avg 1.867663205194709, epsilon 0.8261686238355865\n",
      "\tFinal tour: [0, 5, 2, 4, 9, 8, 6, 3, 7, 1, 0]\n",
      "Episode 20, loss None, running avg 1.8811247540493106, epsilon 0.8179069375972307\n",
      "\tFinal tour: [0, 2, 4, 3, 7, 6, 1, 8, 5, 9, 0]\n",
      "Episode 21, running avg 1.875917489200771, epsilon 0.8097278682212583\n",
      "\tFinal tour: [0, 3, 8, 6, 2, 5, 1, 9, 7, 4, 0]\n",
      "Episode 22, running avg 1.8744878477454137, epsilon 0.8016305895390458\n",
      "\tFinal tour: [0, 1, 4, 9, 2, 6, 7, 8, 5, 3, 0]\n",
      "Episode 23, running avg 1.877703813573973, epsilon 0.7936142836436553\n",
      "\tFinal tour: [0, 3, 4, 5, 1, 9, 6, 7, 2, 8, 0]\n",
      "Episode 24, running avg 1.8929567120913866, epsilon 0.7856781408072188\n",
      "\tFinal tour: [0, 7, 2, 6, 5, 8, 3, 1, 9, 4, 0]\n",
      "Episode 25, running avg 1.899150544951508, epsilon 0.7778213593991465\n",
      "\tFinal tour: [0, 1, 9, 2, 3, 8, 5, 4, 6, 7, 0]\n",
      "Episode 26, running avg 1.8849176149104576, epsilon 0.7700431458051551\n",
      "\tFinal tour: [0, 7, 3, 8, 2, 1, 9, 5, 4, 6, 0]\n",
      "Episode 27, running avg 1.87595659351147, epsilon 0.7623427143471035\n",
      "\tFinal tour: [0, 2, 8, 6, 3, 4, 7, 9, 5, 1, 0]\n",
      "Episode 28, running avg 1.8737889403271668, epsilon 0.7547192872036325\n",
      "\tFinal tour: [0, 4, 8, 1, 3, 6, 5, 7, 2, 9, 0]\n",
      "Episode 29, running avg 1.8735446712899873, epsilon 0.7471720943315961\n",
      "\tFinal tour: [0, 8, 4, 2, 1, 5, 7, 6, 3, 9, 0]\n",
      "Episode 30, loss None, running avg 1.8825056758354257, epsilon 0.7397003733882802\n",
      "\tFinal tour: [0, 9, 1, 2, 4, 7, 6, 3, 5, 8, 0]\n",
      "Episode 31, running avg 1.8826207796308287, epsilon 0.7323033696543974\n",
      "\tFinal tour: [0, 3, 4, 1, 9, 8, 6, 7, 5, 2, 0]\n",
      "Episode 32, running avg 1.889841771142803, epsilon 0.7249803359578534\n",
      "\tFinal tour: [0, 8, 7, 3, 2, 6, 4, 9, 5, 1, 0]\n",
      "Episode 33, running avg 1.8861101705907384, epsilon 0.7177305325982748\n",
      "\tFinal tour: [0, 6, 4, 5, 8, 7, 3, 2, 9, 1, 0]\n",
      "Episode 34, running avg 1.8979997391527572, epsilon 0.7105532272722921\n",
      "\tFinal tour: [0, 9, 7, 6, 8, 1, 3, 2, 5, 4, 0]\n",
      "Episode 35, running avg 1.9138534775624159, epsilon 0.7034476949995692\n",
      "\tFinal tour: [0, 4, 8, 3, 2, 5, 7, 1, 9, 6, 0]\n",
      "Episode 36, running avg 1.9079555159073034, epsilon 0.6964132180495735\n",
      "\tFinal tour: [0, 6, 3, 9, 5, 4, 2, 1, 8, 7, 0]\n",
      "Episode 37, running avg 1.9223066721476214, epsilon 0.6894490858690777\n",
      "\tFinal tour: [0, 9, 1, 5, 8, 2, 3, 6, 4, 7, 0]\n",
      "Episode 38, running avg 1.9160675336178126, epsilon 0.682554595010387\n",
      "\tFinal tour: [0, 7, 4, 5, 6, 1, 9, 3, 8, 2, 0]\n",
      "Episode 39, running avg 1.9185559422615082, epsilon 0.6757290490602831\n",
      "\tFinal tour: [0, 4, 9, 5, 3, 8, 1, 6, 7, 2, 0]\n",
      "Episode 40, loss None, running avg 1.9223083830624472, epsilon 0.6689717585696803\n",
      "\tFinal tour: [0, 9, 7, 3, 4, 6, 2, 5, 8, 1, 0]\n",
      "Episode 41, running avg 1.916959475182059, epsilon 0.6622820409839835\n",
      "\tFinal tour: [0, 7, 4, 9, 8, 5, 2, 3, 6, 1, 0]\n",
      "Episode 42, running avg 1.9158481347560201, epsilon 0.6556592205741436\n",
      "\tFinal tour: [0, 3, 4, 7, 6, 2, 1, 9, 8, 5, 0]\n",
      "Episode 43, running avg 1.9171230323241297, epsilon 0.6491026283684022\n",
      "\tFinal tour: [0, 3, 8, 1, 6, 9, 7, 2, 4, 5, 0]\n",
      "Episode 44, running avg 1.9366460430977648, epsilon 0.6426116020847181\n",
      "\tFinal tour: [0, 9, 1, 5, 6, 2, 4, 3, 8, 7, 0]\n",
      "Episode 45, running avg 1.9415080962446116, epsilon 0.6361854860638709\n",
      "\tFinal tour: [0, 8, 6, 4, 1, 5, 2, 3, 9, 7, 0]\n",
      "Episode 46, running avg 1.9511169203936505, epsilon 0.6298236312032323\n",
      "\tFinal tour: [0, 8, 4, 9, 5, 6, 3, 1, 7, 2, 0]\n",
      "Episode 47, running avg 1.9481821583609067, epsilon 0.6235253948912\n",
      "\tFinal tour: [0, 9, 2, 5, 6, 7, 4, 8, 1, 3, 0]\n",
      "Episode 48, running avg 1.9529992273979, epsilon 0.617290140942288\n",
      "\tFinal tour: [0, 6, 4, 7, 2, 3, 8, 5, 1, 9, 0]\n",
      "Episode 49, running avg 1.959663417205965, epsilon 0.6111172395328651\n",
      "\tFinal tour: [0, 7, 4, 3, 6, 8, 1, 2, 9, 5, 0]\n",
      "Episode 50, loss None, running avg 1.9578797918204114, epsilon 0.6050060671375365\n",
      "\tFinal tour: [0, 4, 8, 9, 6, 7, 1, 2, 5, 3, 0]\n",
      "Episode 51, running avg 1.9553244547393613, epsilon 0.5989560064661611\n",
      "\tFinal tour: [0, 9, 7, 5, 2, 3, 8, 1, 4, 6, 0]\n",
      "Episode 52, running avg 1.9686723350567503, epsilon 0.5929664464014994\n",
      "\tFinal tour: [0, 9, 1, 8, 4, 7, 5, 3, 2, 6, 0]\n",
      "Episode 53, running avg 1.9687300506904182, epsilon 0.5870367819374844\n",
      "\tFinal tour: [0, 9, 1, 3, 4, 7, 5, 8, 6, 2, 0]\n",
      "Episode 54, running avg 1.9688464447530354, epsilon 0.5811664141181095\n",
      "\tFinal tour: [0, 9, 8, 4, 6, 2, 5, 1, 3, 7, 0]\n",
      "Episode 55, running avg 1.9657577209882378, epsilon 0.5753547499769285\n",
      "\tFinal tour: [0, 9, 4, 5, 8, 1, 2, 7, 3, 6, 0]\n",
      "Episode 56, running avg 1.9643051410271941, epsilon 0.5696012024771592\n",
      "\tFinal tour: [0, 2, 9, 7, 4, 5, 3, 6, 1, 8, 0]\n",
      "Episode 57, running avg 1.9698197622028188, epsilon 0.5639051904523876\n",
      "\tFinal tour: [0, 1, 4, 2, 5, 3, 6, 8, 9, 7, 0]\n",
      "Episode 58, running avg 1.9664246986394653, epsilon 0.5582661385478638\n",
      "\tFinal tour: [0, 6, 2, 4, 7, 9, 3, 1, 5, 8, 0]\n",
      "Episode 59, running avg 1.967674719723245, epsilon 0.5526834771623851\n",
      "\tFinal tour: [0, 8, 9, 1, 2, 5, 4, 7, 6, 3, 0]\n",
      "Episode 60, loss None, running avg 1.9750071868357943, epsilon 0.5471566423907612\n",
      "\tFinal tour: [0, 9, 8, 5, 6, 7, 3, 2, 1, 4, 0]\n",
      "Episode 61, running avg 1.9846927804680423, epsilon 0.5416850759668536\n",
      "\tFinal tour: [0, 8, 6, 3, 2, 4, 9, 7, 5, 1, 0]\n",
      "Episode 62, running avg 1.98678544354605, epsilon 0.536268225207185\n",
      "\tFinal tour: [0, 9, 5, 8, 7, 6, 1, 4, 3, 2, 0]\n",
      "Episode 63, running avg 1.9885457062988976, epsilon 0.5309055429551132\n",
      "\tFinal tour: [0, 8, 3, 6, 4, 7, 9, 5, 2, 1, 0]\n",
      "Episode 64, running avg 1.9873420221742124, epsilon 0.525596487525562\n",
      "\tFinal tour: [0, 9, 7, 5, 2, 8, 3, 4, 6, 1, 0]\n",
      "Episode 65, running avg 1.986288325673666, epsilon 0.5203405226503064\n",
      "\tFinal tour: [0, 9, 5, 2, 1, 3, 4, 6, 8, 7, 0]\n",
      "Episode 66, running avg 1.9806561457834295, epsilon 0.5151371174238033\n",
      "\tFinal tour: [0, 6, 1, 3, 4, 8, 9, 5, 2, 7, 0]\n",
      "Episode 67, running avg 1.9833033752765037, epsilon 0.5099857462495653\n",
      "\tFinal tour: [0, 8, 2, 6, 3, 9, 1, 4, 5, 7, 0]\n",
      "Episode 68, running avg 1.9758130350698233, epsilon 0.5048858887870696\n",
      "\tFinal tour: [0, 6, 4, 3, 1, 2, 5, 8, 9, 7, 0]\n",
      "Episode 69, running avg 1.9797304634449204, epsilon 0.4998370298991989\n",
      "\tFinal tour: [0, 9, 3, 6, 7, 2, 8, 5, 1, 4, 0]\n",
      "Episode 70, loss None, running avg 1.9802970687523032, epsilon 0.49483865960020695\n",
      "\tFinal tour: [0, 7, 9, 8, 6, 4, 1, 2, 5, 3, 0]\n",
      "Episode 71, running avg 1.980067991302486, epsilon 0.4898902730042049\n",
      "\tFinal tour: [0, 2, 3, 1, 7, 6, 8, 9, 5, 4, 0]\n",
      "Episode 72, running avg 1.9803618931234395, epsilon 0.48499137027416284\n",
      "\tFinal tour: [0, 2, 5, 6, 7, 8, 4, 3, 9, 1, 0]\n",
      "Episode 73, running avg 1.9866726160709107, epsilon 0.4801414565714212\n",
      "\tFinal tour: [0, 9, 7, 3, 1, 6, 2, 5, 8, 4, 0]\n",
      "Episode 74, running avg 1.9911324670865835, epsilon 0.475340042005707\n",
      "\tFinal tour: [0, 2, 5, 3, 6, 9, 4, 8, 7, 1, 0]\n",
      "Episode 75, running avg 1.9904892979656714, epsilon 0.47058664158564995\n",
      "\tFinal tour: [0, 9, 5, 4, 1, 7, 8, 6, 3, 2, 0]\n",
      "Episode 76, running avg 1.9916981185943754, epsilon 0.4658807751697934\n",
      "\tFinal tour: [0, 9, 5, 4, 7, 1, 6, 2, 8, 3, 0]\n",
      "Episode 77, running avg 1.9934687965773137, epsilon 0.4612219674180955\n",
      "\tFinal tour: [0, 2, 1, 3, 6, 7, 5, 9, 4, 8, 0]\n",
      "Episode 78, running avg 1.9894205110968703, epsilon 0.45660974774391455\n",
      "\tFinal tour: [0, 4, 1, 3, 2, 6, 9, 7, 5, 8, 0]\n",
      "Episode 79, running avg 1.9868564396783668, epsilon 0.4520436502664754\n",
      "\tFinal tour: [0, 3, 4, 1, 6, 7, 8, 5, 9, 2, 0]\n",
      "Episode 80, loss None, running avg 1.9897082277234148, epsilon 0.44752321376381066\n",
      "\tFinal tour: [0, 6, 3, 8, 9, 7, 4, 2, 5, 1, 0]\n",
      "Episode 81, running avg 1.99440011359264, epsilon 0.44304798162617254\n",
      "\tFinal tour: [0, 5, 1, 6, 4, 8, 2, 3, 7, 9, 0]\n",
      "Episode 82, running avg 1.9994295644307074, epsilon 0.4386175018099108\n",
      "\tFinal tour: [0, 8, 9, 5, 1, 7, 6, 4, 2, 3, 0]\n",
      "Episode 83, running avg 2.0037837863441608, epsilon 0.4342313267918117\n",
      "\tFinal tour: [0, 1, 4, 8, 5, 6, 9, 2, 3, 7, 0]\n",
      "Episode 84, running avg 1.9992275191732203, epsilon 0.4298890135238936\n",
      "\tFinal tour: [0, 1, 9, 3, 2, 4, 8, 5, 6, 7, 0]\n",
      "Episode 85, running avg 2.005332716560686, epsilon 0.42559012338865465\n",
      "\tFinal tour: [0, 9, 3, 6, 2, 7, 4, 8, 5, 1, 0]\n",
      "Episode 86, running avg 2.0040481618228587, epsilon 0.4213342221547681\n",
      "\tFinal tour: [0, 9, 6, 5, 4, 7, 3, 8, 1, 2, 0]\n",
      "Episode 87, running avg 2.003725425766002, epsilon 0.41712087993322045\n",
      "\tFinal tour: [0, 6, 8, 1, 3, 7, 4, 2, 9, 5, 0]\n",
      "Episode 88, running avg 2.0024002316178184, epsilon 0.41294967113388825\n",
      "\tFinal tour: [0, 1, 8, 5, 3, 4, 7, 2, 9, 6, 0]\n",
      "Episode 89, running avg 2.0070455734780546, epsilon 0.40882017442254937\n",
      "\tFinal tour: [0, 8, 3, 4, 6, 5, 9, 2, 7, 1, 0]\n",
      "Episode 90, loss None, running avg 2.010594709920103, epsilon 0.4047319726783239\n",
      "\tFinal tour: [0, 5, 1, 4, 7, 2, 3, 9, 6, 8, 0]\n",
      "Episode 91, running avg 2.008158838690969, epsilon 0.40068465295154065\n",
      "\tFinal tour: [0, 4, 6, 8, 1, 3, 7, 5, 9, 2, 0]\n",
      "Episode 92, running avg 2.013341109423764, epsilon 0.39667780642202527\n",
      "\tFinal tour: [0, 2, 1, 3, 9, 7, 5, 6, 8, 4, 0]\n",
      "Episode 93, running avg 2.0118923905274717, epsilon 0.392711028357805\n",
      "\tFinal tour: [0, 4, 3, 2, 8, 9, 1, 5, 6, 7, 0]\n",
      "Episode 94, running avg 2.0119440290158854, epsilon 0.38878391807422696\n",
      "\tFinal tour: [0, 4, 2, 5, 6, 9, 3, 1, 8, 7, 0]\n",
      "Episode 95, running avg 2.0085000995715094, epsilon 0.3848960788934847\n",
      "\tFinal tour: [0, 4, 8, 6, 5, 3, 2, 7, 9, 1, 0]\n",
      "Episode 96, running avg 2.0113322532752416, epsilon 0.38104711810454983\n",
      "\tFinal tour: [0, 7, 4, 1, 2, 6, 9, 8, 5, 3, 0]\n",
      "Episode 97, running avg 2.0150004249439344, epsilon 0.37723664692350434\n",
      "\tFinal tour: [0, 3, 2, 7, 5, 9, 8, 1, 6, 4, 0]\n",
      "Episode 98, running avg 2.014701759126482, epsilon 0.37346428045426927\n",
      "\tFinal tour: [0, 9, 6, 3, 2, 5, 7, 1, 4, 8, 0]\n",
      "Episode 99, running avg 2.014618641643421, epsilon 0.36972963764972655\n",
      "\tFinal tour: [0, 8, 5, 2, 4, 6, 3, 1, 9, 7, 0]\n",
      "Episode 100, loss None, running avg 2.0147985257760292, epsilon 0.36603234127322926\n",
      "\tFinal tour: [0, 9, 6, 3, 7, 8, 4, 5, 2, 1, 0]\n",
      "Episode 101, running avg 2.0161759847233167, epsilon 0.36237201786049694\n",
      "\tFinal tour: [0, 7, 2, 6, 5, 8, 3, 1, 9, 4, 0]\n",
      "Episode 102, running avg 2.0151422188329975, epsilon 0.358748297681892\n",
      "\tFinal tour: [0, 3, 4, 2, 5, 6, 9, 7, 1, 8, 0]\n",
      "Episode 103, running avg 2.0128714865672652, epsilon 0.35516081470507305\n",
      "\tFinal tour: [0, 9, 8, 7, 2, 4, 3, 6, 1, 5, 0]\n",
      "Episode 104, running avg 2.019851723773928, epsilon 0.3516092065580223\n",
      "\tFinal tour: [0, 3, 5, 9, 4, 8, 7, 6, 1, 2, 0]\n",
      "Episode 105, running avg 2.0204124818574623, epsilon 0.34809311449244207\n",
      "\tFinal tour: [0, 9, 8, 2, 1, 6, 5, 3, 7, 4, 0]\n",
      "Episode 106, running avg 2.017878160006831, epsilon 0.34461218334751764\n",
      "\tFinal tour: [0, 9, 5, 7, 6, 2, 1, 8, 3, 4, 0]\n",
      "Episode 107, running avg 2.0157718433239644, epsilon 0.34116606151404244\n",
      "\tFinal tour: [0, 2, 4, 3, 7, 6, 8, 9, 5, 1, 0]\n",
      "Episode 108, running avg 2.019122043496516, epsilon 0.337754400898902\n",
      "\tFinal tour: [0, 7, 1, 6, 5, 3, 2, 4, 9, 8, 0]\n",
      "Episode 109, running avg 2.025588262093954, epsilon 0.334376856889913\n",
      "\tFinal tour: [0, 9, 4, 1, 5, 3, 8, 6, 7, 2, 0]\n",
      "Episode 110, loss None, running avg 2.032869259752648, epsilon 0.33103308832101386\n",
      "\tFinal tour: [0, 1, 5, 4, 9, 3, 6, 8, 7, 2, 0]\n",
      "Episode 111, running avg 2.0387226904986293, epsilon 0.3277227574378037\n",
      "\tFinal tour: [0, 9, 6, 3, 8, 1, 2, 7, 4, 5, 0]\n",
      "Episode 112, running avg 2.0369618651879287, epsilon 0.3244455298634257\n",
      "\tFinal tour: [0, 3, 1, 9, 8, 7, 6, 4, 2, 5, 0]\n",
      "Episode 113, running avg 2.0392533938540343, epsilon 0.3212010745647914\n",
      "\tFinal tour: [0, 8, 3, 9, 7, 5, 4, 6, 2, 1, 0]\n",
      "Episode 114, running avg 2.045083054036118, epsilon 0.3179890638191435\n",
      "\tFinal tour: [0, 3, 2, 6, 1, 9, 7, 5, 8, 4, 0]\n",
      "Episode 115, running avg 2.0430586209250547, epsilon 0.31480917318095203\n",
      "\tFinal tour: [0, 5, 9, 8, 1, 4, 2, 7, 3, 6, 0]\n",
      "Episode 116, running avg 2.0388719014010253, epsilon 0.3116610814491425\n",
      "\tFinal tour: [0, 4, 1, 6, 5, 3, 2, 8, 9, 7, 0]\n",
      "Episode 117, running avg 2.041257971677827, epsilon 0.30854447063465107\n",
      "\tFinal tour: [0, 1, 3, 6, 2, 5, 4, 9, 7, 8, 0]\n",
      "Episode 118, running avg 2.0488139616118324, epsilon 0.30545902592830454\n",
      "\tFinal tour: [0, 8, 9, 7, 6, 4, 1, 3, 2, 5, 0]\n",
      "Episode 119, running avg 2.050600005677156, epsilon 0.3024044356690215\n",
      "\tFinal tour: [0, 3, 1, 7, 4, 6, 2, 9, 5, 8, 0]\n",
      "Episode 120, loss None, running avg 2.0464588444304224, epsilon 0.29938039131233124\n",
      "\tFinal tour: [0, 1, 9, 2, 5, 6, 3, 8, 7, 4, 0]\n",
      "Episode 121, running avg 2.0483237603663498, epsilon 0.2963865873992079\n",
      "\tFinal tour: [0, 9, 1, 3, 2, 8, 5, 7, 4, 6, 0]\n",
      "Episode 122, running avg 2.048693024953847, epsilon 0.29342272152521587\n",
      "\tFinal tour: [0, 6, 4, 9, 5, 8, 1, 7, 2, 3, 0]\n",
      "Episode 123, running avg 2.0533823535065725, epsilon 0.2904884943099637\n",
      "\tFinal tour: [0, 6, 9, 5, 4, 8, 2, 3, 1, 7, 0]\n",
      "Episode 124, running avg 2.0553257153252718, epsilon 0.28758360936686406\n",
      "\tFinal tour: [0, 5, 1, 6, 9, 8, 7, 2, 4, 3, 0]\n",
      "Episode 125, running avg 2.059993488391546, epsilon 0.2847077732731954\n",
      "\tFinal tour: [0, 3, 4, 5, 7, 8, 2, 1, 9, 6, 0]\n",
      "Episode 126, running avg 2.068865598670038, epsilon 0.28186069554046345\n",
      "\tFinal tour: [0, 8, 1, 9, 2, 3, 7, 5, 4, 6, 0]\n",
      "Episode 127, running avg 2.0734357824861442, epsilon 0.2790420885850588\n",
      "\tFinal tour: [0, 8, 4, 3, 2, 9, 5, 6, 1, 7, 0]\n",
      "Episode 128, running avg 2.0749329267933585, epsilon 0.2762516676992082\n",
      "\tFinal tour: [0, 7, 6, 4, 9, 2, 1, 5, 3, 8, 0]\n",
      "Episode 129, running avg 2.079829741113816, epsilon 0.27348915102221616\n",
      "\tFinal tour: [0, 3, 8, 7, 4, 1, 2, 5, 6, 9, 0]\n",
      "Episode 130, loss None, running avg 2.088470044873789, epsilon 0.270754259511994\n",
      "\tFinal tour: [0, 7, 4, 3, 6, 2, 9, 8, 5, 1, 0]\n",
      "Episode 131, running avg 2.091678514625676, epsilon 0.26804671691687404\n",
      "\tFinal tour: [0, 3, 1, 2, 7, 4, 9, 8, 6, 5, 0]\n",
      "Episode 132, running avg 2.0939618368941826, epsilon 0.2653662497477053\n",
      "\tFinal tour: [0, 8, 2, 3, 6, 1, 4, 7, 9, 5, 0]\n",
      "Episode 133, running avg 2.094522550218846, epsilon 0.2627125872502282\n",
      "\tFinal tour: [0, 3, 4, 5, 7, 1, 2, 9, 6, 8, 0]\n",
      "Episode 134, running avg 2.0947000451766984, epsilon 0.2600854613777259\n",
      "\tFinal tour: [0, 9, 7, 1, 3, 8, 2, 5, 6, 4, 0]\n",
      "Episode 135, running avg 2.0900005911318207, epsilon 0.2574846067639487\n",
      "\tFinal tour: [0, 4, 7, 2, 8, 3, 5, 9, 1, 6, 0]\n",
      "Episode 136, running avg 2.097810400736863, epsilon 0.2549097606963092\n",
      "\tFinal tour: [0, 9, 2, 7, 4, 8, 1, 5, 6, 3, 0]\n",
      "Episode 137, running avg 2.0914554836216586, epsilon 0.2523606630893461\n",
      "\tFinal tour: [0, 4, 3, 7, 9, 6, 2, 5, 8, 1, 0]\n",
      "Episode 138, running avg 2.096329732691762, epsilon 0.24983705645845267\n",
      "\tFinal tour: [0, 5, 9, 3, 1, 8, 4, 6, 2, 7, 0]\n",
      "Episode 139, running avg 2.098444772015779, epsilon 0.24733868589386815\n",
      "\tFinal tour: [0, 6, 3, 2, 8, 9, 1, 4, 5, 7, 0]\n",
      "Episode 140, loss None, running avg 2.0967287158660795, epsilon 0.24486529903492946\n",
      "\tFinal tour: [0, 9, 1, 5, 3, 4, 2, 6, 7, 8, 0]\n",
      "Episode 141, running avg 2.102598825298799, epsilon 0.24241664604458016\n",
      "\tFinal tour: [0, 7, 3, 1, 8, 5, 6, 2, 4, 9, 0]\n",
      "Episode 142, running avg 2.1044867672941034, epsilon 0.23999247958413436\n",
      "\tFinal tour: [0, 9, 4, 5, 1, 7, 3, 8, 2, 6, 0]\n",
      "Episode 143, running avg 2.106288822430935, epsilon 0.23759255478829303\n",
      "\tFinal tour: [0, 4, 3, 1, 2, 9, 8, 7, 6, 5, 0]\n",
      "Episode 144, running avg 2.1063404454736885, epsilon 0.2352166292404101\n",
      "\tFinal tour: [0, 7, 1, 8, 6, 5, 3, 2, 4, 9, 0]\n",
      "Episode 145, running avg 2.1078834509692643, epsilon 0.232864462948006\n",
      "\tFinal tour: [0, 3, 6, 4, 7, 5, 9, 8, 1, 2, 0]\n",
      "Episode 146, running avg 2.10869379343215, epsilon 0.23053581831852593\n",
      "\tFinal tour: [0, 8, 1, 3, 9, 5, 2, 4, 7, 6, 0]\n",
      "Episode 147, running avg 2.1099376808909662, epsilon 0.22823046013534068\n",
      "\tFinal tour: [0, 3, 5, 9, 2, 1, 6, 7, 4, 8, 0]\n",
      "Episode 148, running avg 2.1091517659204095, epsilon 0.22594815553398728\n",
      "\tFinal tour: [0, 1, 8, 6, 5, 4, 9, 3, 7, 2, 0]\n",
      "Episode 149, running avg 2.107610375681297, epsilon 0.22368867397864742\n",
      "\tFinal tour: [0, 6, 3, 5, 4, 2, 7, 8, 9, 1, 0]\n",
      "Episode 150, loss None, running avg 2.1113816496508404, epsilon 0.22145178723886094\n",
      "\tFinal tour: [0, 8, 5, 4, 1, 6, 3, 2, 7, 9, 0]\n",
      "Episode 151, running avg 2.1147399508816616, epsilon 0.21923726936647234\n",
      "\tFinal tour: [0, 6, 8, 4, 1, 9, 2, 3, 5, 7, 0]\n",
      "Episode 152, running avg 2.1091682365048934, epsilon 0.2170448966728076\n",
      "\tFinal tour: [0, 3, 8, 5, 9, 4, 1, 6, 7, 2, 0]\n",
      "Episode 153, running avg 2.1071163713085537, epsilon 0.21487444770607952\n",
      "\tFinal tour: [0, 7, 1, 6, 8, 4, 5, 9, 2, 3, 0]\n",
      "Episode 154, running avg 2.1084920087413854, epsilon 0.21272570322901874\n",
      "\tFinal tour: [0, 5, 8, 1, 2, 7, 3, 9, 4, 6, 0]\n",
      "Episode 155, running avg 2.112478181577519, epsilon 0.21059844619672854\n",
      "\tFinal tour: [0, 9, 5, 8, 1, 7, 4, 3, 6, 2, 0]\n",
      "Episode 156, running avg 2.1142047356510547, epsilon 0.20849246173476127\n",
      "\tFinal tour: [0, 7, 4, 2, 8, 9, 6, 5, 1, 3, 0]\n",
      "Episode 157, running avg 2.111781468926725, epsilon 0.20640753711741366\n",
      "\tFinal tour: [0, 6, 4, 9, 3, 7, 2, 8, 5, 1, 0]\n",
      "Episode 158, running avg 2.114733187116438, epsilon 0.20434346174623952\n",
      "\tFinal tour: [0, 6, 5, 9, 1, 7, 3, 4, 8, 2, 0]\n",
      "Episode 159, running avg 2.1172677003239717, epsilon 0.20230002712877712\n",
      "\tFinal tour: [0, 5, 1, 4, 2, 3, 8, 6, 7, 9, 0]\n",
      "Episode 160, loss None, running avg 2.1145784966050845, epsilon 0.20027702685748935\n",
      "\tFinal tour: [0, 5, 1, 9, 2, 8, 3, 6, 4, 7, 0]\n",
      "Episode 161, running avg 2.1148810144178287, epsilon 0.19827425658891445\n",
      "\tFinal tour: [0, 4, 5, 2, 1, 9, 8, 3, 6, 7, 0]\n",
      "Episode 162, running avg 2.111218024132357, epsilon 0.1962915140230253\n",
      "\tFinal tour: [0, 2, 6, 9, 7, 5, 4, 8, 1, 3, 0]\n",
      "Episode 163, running avg 2.1109207804424215, epsilon 0.19432859888279505\n",
      "\tFinal tour: [0, 9, 8, 6, 2, 3, 5, 7, 4, 1, 0]\n",
      "Episode 164, running avg 2.11507972011433, epsilon 0.1923853128939671\n",
      "\tFinal tour: [0, 9, 5, 8, 3, 7, 6, 4, 2, 1, 0]\n",
      "Episode 165, running avg 2.1168597826522593, epsilon 0.19046145976502743\n",
      "\tFinal tour: [0, 6, 4, 2, 1, 3, 5, 9, 7, 8, 0]\n",
      "Episode 166, running avg 2.1230325683295557, epsilon 0.18855684516737714\n",
      "\tFinal tour: [0, 6, 9, 2, 4, 5, 7, 8, 3, 1, 0]\n",
      "Episode 167, running avg 2.120662780204345, epsilon 0.18667127671570335\n",
      "\tFinal tour: [0, 4, 7, 3, 9, 8, 2, 5, 1, 6, 0]\n",
      "Episode 168, running avg 2.1270307389883034, epsilon 0.18480456394854633\n",
      "\tFinal tour: [0, 2, 9, 8, 5, 1, 3, 6, 4, 7, 0]\n",
      "Episode 169, running avg 2.1293690663465323, epsilon 0.18295651830906087\n",
      "\tFinal tour: [0, 7, 4, 2, 8, 9, 5, 1, 3, 6, 0]\n",
      "Episode 170, loss None, running avg 2.1308469742104994, epsilon 0.18112695312597027\n",
      "\tFinal tour: [0, 4, 2, 6, 1, 8, 7, 3, 9, 5, 0]\n",
      "Episode 171, running avg 2.1328119527940768, epsilon 0.17931568359471056\n",
      "\tFinal tour: [0, 9, 8, 2, 6, 4, 3, 7, 5, 1, 0]\n",
      "Episode 172, running avg 2.1316327096213405, epsilon 0.17752252675876345\n",
      "\tFinal tour: [0, 5, 1, 9, 8, 3, 6, 4, 2, 7, 0]\n",
      "Episode 173, running avg 2.1290535917758624, epsilon 0.17574730149117582\n",
      "\tFinal tour: [0, 9, 5, 2, 3, 1, 8, 4, 7, 6, 0]\n",
      "Episode 174, running avg 2.1244512298574905, epsilon 0.17398982847626407\n",
      "\tFinal tour: [0, 9, 3, 1, 4, 5, 8, 2, 7, 6, 0]\n",
      "Episode 175, running avg 2.1292180273674477, epsilon 0.17224993019150142\n",
      "\tFinal tour: [0, 1, 2, 6, 5, 4, 3, 9, 7, 8, 0]\n",
      "Episode 176, running avg 2.1275799807087945, epsilon 0.1705274308895864\n",
      "\tFinal tour: [0, 2, 3, 1, 4, 7, 8, 9, 5, 6, 0]\n",
      "Episode 177, running avg 2.123741499616202, epsilon 0.16882215658069055\n",
      "\tFinal tour: [0, 1, 5, 8, 3, 2, 9, 7, 4, 6, 0]\n",
      "Episode 178, running avg 2.1266902607230582, epsilon 0.16713393501488363\n",
      "\tFinal tour: [0, 9, 5, 2, 1, 3, 7, 4, 8, 6, 0]\n",
      "Episode 179, running avg 2.124538421595157, epsilon 0.16546259566473479\n",
      "\tFinal tour: [0, 5, 1, 2, 4, 8, 3, 9, 7, 6, 0]\n",
      "Episode 180, loss None, running avg 2.1297474383195136, epsilon 0.16380796970808745\n",
      "\tFinal tour: [0, 7, 4, 1, 2, 9, 8, 5, 6, 3, 0]\n",
      "Episode 181, running avg 2.1283094544686527, epsilon 0.16216989001100657\n",
      "\tFinal tour: [0, 6, 3, 2, 5, 7, 4, 9, 8, 1, 0]\n",
      "Episode 182, running avg 2.1261032553387476, epsilon 0.1605481911108965\n",
      "\tFinal tour: [0, 7, 2, 8, 9, 3, 6, 1, 4, 5, 0]\n",
      "Episode 183, running avg 2.124037660437185, epsilon 0.15894270919978754\n",
      "\tFinal tour: [0, 4, 6, 5, 7, 3, 2, 9, 8, 1, 0]\n",
      "Episode 184, running avg 2.126706122105068, epsilon 0.15735328210778965\n",
      "\tFinal tour: [0, 6, 4, 9, 5, 8, 1, 3, 2, 7, 0]\n",
      "Episode 185, running avg 2.1270362961768767, epsilon 0.15577974928671176\n",
      "\tFinal tour: [0, 9, 5, 3, 8, 6, 7, 4, 2, 1, 0]\n",
      "Episode 186, running avg 2.1303764603722057, epsilon 0.15422195179384465\n",
      "\tFinal tour: [0, 5, 3, 7, 2, 9, 4, 8, 1, 6, 0]\n",
      "Episode 187, running avg 2.131641268683177, epsilon 0.1526797322759062\n",
      "\tFinal tour: [0, 5, 2, 4, 1, 9, 8, 6, 7, 3, 0]\n",
      "Episode 188, running avg 2.1333085544432207, epsilon 0.15115293495314713\n",
      "\tFinal tour: [0, 7, 3, 1, 8, 5, 4, 9, 2, 6, 0]\n",
      "Episode 189, running avg 2.128696019898693, epsilon 0.14964140560361566\n",
      "\tFinal tour: [0, 2, 8, 9, 6, 3, 1, 4, 7, 5, 0]\n",
      "Episode 190, loss None, running avg 2.126506715425903, epsilon 0.1481449915475795\n",
      "\tFinal tour: [0, 7, 9, 8, 6, 2, 3, 5, 1, 4, 0]\n",
      "Episode 191, running avg 2.1339719401266506, epsilon 0.1466635416321037\n",
      "\tFinal tour: [0, 7, 1, 8, 6, 9, 2, 4, 3, 5, 0]\n",
      "Episode 192, running avg 2.131882629751221, epsilon 0.14519690621578268\n",
      "\tFinal tour: [0, 9, 7, 3, 6, 1, 5, 2, 8, 4, 0]\n",
      "Episode 193, running avg 2.1353329854406375, epsilon 0.14374493715362485\n",
      "\tFinal tour: [0, 6, 8, 4, 1, 3, 5, 2, 7, 9, 0]\n",
      "Episode 194, running avg 2.136458126909913, epsilon 0.1423074877820886\n",
      "\tFinal tour: [0, 1, 6, 8, 2, 5, 3, 4, 7, 9, 0]\n",
      "Episode 195, running avg 2.1374278262146627, epsilon 0.1408844129042677\n",
      "\tFinal tour: [0, 7, 4, 2, 8, 9, 5, 1, 3, 6, 0]\n",
      "Episode 196, running avg 2.1362957938769496, epsilon 0.13947556877522502\n",
      "\tFinal tour: [0, 8, 9, 2, 4, 7, 3, 1, 6, 5, 0]\n",
      "Episode 197, running avg 2.132869932473018, epsilon 0.13808081308747278\n",
      "\tFinal tour: [0, 4, 8, 2, 1, 7, 6, 3, 5, 9, 0]\n",
      "Episode 198, running avg 2.131349064431862, epsilon 0.13670000495659804\n",
      "\tFinal tour: [0, 3, 5, 9, 2, 1, 6, 7, 4, 8, 0]\n",
      "Episode 199, running avg 2.1322924328996367, epsilon 0.13533300490703207\n",
      "\tFinal tour: [0, 1, 5, 8, 9, 2, 7, 3, 6, 4, 0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 379\u001B[0m\n\u001B[0;32m    373\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(hyperparams\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrepetitions\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m1\u001B[39m)):\n\u001B[0;32m    374\u001B[0m     tsp_multi \u001B[38;5;241m=\u001B[39m QLearningTsp(\n\u001B[0;32m    375\u001B[0m         hyperparams\u001B[38;5;241m=\u001B[39mhyperparams,\n\u001B[0;32m    376\u001B[0m         path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/save_path/\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    377\u001B[0m     )\n\u001B[1;32m--> 379\u001B[0m     \u001B[43mtsp_multi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mperform_episodes\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    380\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_instances\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhyperparams\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnum_instances\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    381\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[7], line 337\u001B[0m, in \u001B[0;36mQLearningTsp.perform_episodes\u001B[1;34m(self, num_instances)\u001B[0m\n\u001B[0;32m    335\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmemory) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_size:\n\u001B[0;32m    336\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m episode \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mupdate_after \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 337\u001B[0m         loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    338\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    339\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpisode \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepisode\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, loss \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, running avg \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrunning_avg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, epsilon \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepsilon\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    340\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124mFinal tour: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtour\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[7], line 217\u001B[0m, in \u001B[0;36mQLearningTsp.train_step\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m    216\u001B[0m exp_val_masks \u001B[38;5;241m=\u001B[39m get_masks_for_actions(edge_weights, partial_tours)\n\u001B[1;32m--> 217\u001B[0m exp_values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstates\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreadout_op\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    218\u001B[0m q_values_masked \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msum(exp_values\u001B[38;5;241m.\u001B[39mdetach() \u001B[38;5;241m*\u001B[39m exp_val_masks, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    219\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_fun(target_q_values, q_values_masked)\n",
      "File \u001B[1;32m~\\Documents\\repositories\\QML-QGNN\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\repositories\\QML-QGNN\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[7], line 20\u001B[0m, in \u001B[0;36mQModel.forward\u001B[1;34m(self, input_data, observables)\u001B[0m\n\u001B[0;32m     14\u001B[0m qnn \u001B[38;5;241m=\u001B[39m EstimatorQNN(\n\u001B[0;32m     15\u001B[0m     circuit\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcircuit,\n\u001B[0;32m     16\u001B[0m     input_params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcircuit\u001B[38;5;241m.\u001B[39mparameters,\n\u001B[0;32m     17\u001B[0m     observables\u001B[38;5;241m=\u001B[39mobservables\n\u001B[0;32m     18\u001B[0m )\n\u001B[0;32m     19\u001B[0m qnn \u001B[38;5;241m=\u001B[39m TorchConnector(qnn)\n\u001B[1;32m---> 20\u001B[0m expectation_values \u001B[38;5;241m=\u001B[39m \u001B[43mqnn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mencoding_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m expectation_values\n",
      "File \u001B[1;32m~\\Documents\\repositories\\QML-QGNN\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\repositories\\QML-QGNN\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\repositories\\QML-QGNN\\venv\\Lib\\site-packages\\qiskit_machine_learning\\connectors\\torch_connector.py:333\u001B[0m, in \u001B[0;36mTorchConnector.forward\u001B[1;34m(self, input_data)\u001B[0m\n\u001B[0;32m    324\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Forward pass.\u001B[39;00m\n\u001B[0;32m    325\u001B[0m \n\u001B[0;32m    326\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    330\u001B[0m \u001B[38;5;124;03m    Result of forward pass of this model.\u001B[39;00m\n\u001B[0;32m    331\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    332\u001B[0m input_ \u001B[38;5;241m=\u001B[39m input_data \u001B[38;5;28;01mif\u001B[39;00m input_data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m--> 333\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mTorchConnector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_TorchNNFunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    334\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_neural_network\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sparse\u001B[49m\n\u001B[0;32m    335\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\repositories\\QML-QGNN\\venv\\Lib\\site-packages\\torch\\autograd\\function.py:539\u001B[0m, in \u001B[0;36mFunction.apply\u001B[1;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[0;32m    536\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_are_functorch_transforms_active():\n\u001B[0;32m    537\u001B[0m     \u001B[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001B[39;00m\n\u001B[0;32m    538\u001B[0m     args \u001B[38;5;241m=\u001B[39m _functorch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39munwrap_dead_wrappers(args)\n\u001B[1;32m--> 539\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m    541\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39msetup_context \u001B[38;5;241m==\u001B[39m _SingleLevelFunction\u001B[38;5;241m.\u001B[39msetup_context:\n\u001B[0;32m    542\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    543\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIn order to use an autograd.Function with functorch transforms \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    544\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    545\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstaticmethod. For more details, please see \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    546\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    547\u001B[0m     )\n",
      "File \u001B[1;32m~\\Documents\\repositories\\QML-QGNN\\venv\\Lib\\site-packages\\qiskit_machine_learning\\connectors\\torch_connector.py:100\u001B[0m, in \u001B[0;36mTorchConnector._TorchNNFunction.forward\u001B[1;34m(ctx, input_data, weights, neural_network, sparse)\u001B[0m\n\u001B[0;32m     95\u001B[0m ctx\u001B[38;5;241m.\u001B[39msave_for_backward(input_data, weights)\n\u001B[0;32m     97\u001B[0m \u001B[38;5;66;03m# Detach the tensors and move it to CPU as we need numpy array to compute gradients\u001B[39;00m\n\u001B[0;32m     98\u001B[0m \u001B[38;5;66;03m# of the quantum neural network. If the tensors are on CPU already this does nothing.\u001B[39;00m\n\u001B[0;32m     99\u001B[0m \u001B[38;5;66;03m# Some other tensors down below are also moved to CPU for computations.\u001B[39;00m\n\u001B[1;32m--> 100\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mneural_network\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    101\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetach\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetach\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    102\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ctx\u001B[38;5;241m.\u001B[39msparse:\n\u001B[0;32m    104\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m neural_network\u001B[38;5;241m.\u001B[39msparse:\n",
      "File \u001B[1;32m~\\Documents\\repositories\\QML-QGNN\\venv\\Lib\\site-packages\\qiskit_machine_learning\\neural_networks\\neural_network.py:226\u001B[0m, in \u001B[0;36mNeuralNetwork.forward\u001B[1;34m(self, input_data, weights)\u001B[0m\n\u001B[0;32m    224\u001B[0m input_, shape \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_input(input_data)\n\u001B[0;32m    225\u001B[0m weights_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_weights(weights)\n\u001B[1;32m--> 226\u001B[0m output_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights_\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    227\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_forward_output(output_data, shape)\n",
      "File \u001B[1;32m~\\Documents\\repositories\\QML-QGNN\\venv\\Lib\\site-packages\\qiskit_machine_learning\\neural_networks\\estimator_qnn.py:222\u001B[0m, in \u001B[0;36mEstimatorQNN._forward\u001B[1;34m(self, input_data, weights)\u001B[0m\n\u001B[0;32m    216\u001B[0m job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimator\u001B[38;5;241m.\u001B[39mrun(\n\u001B[0;32m    217\u001B[0m     [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_circuit] \u001B[38;5;241m*\u001B[39m num_samples \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_shape[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m    218\u001B[0m     [op \u001B[38;5;28;01mfor\u001B[39;00m op \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_observables \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_samples)],\n\u001B[0;32m    219\u001B[0m     np\u001B[38;5;241m.\u001B[39mtile(parameter_values_, (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_shape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m1\u001B[39m)),\n\u001B[0;32m    220\u001B[0m )\n\u001B[0;32m    221\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 222\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[0;32m    224\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m QiskitMachineLearningError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEstimator job failed.\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mexc\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\repositories\\QML-QGNN\\venv\\Lib\\site-packages\\qiskit\\primitives\\primitive_job.py:55\u001B[0m, in \u001B[0;36mPrimitiveJob.result\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Return the results of the job.\"\"\"\u001B[39;00m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_submitted()\n\u001B[1;32m---> 55\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_future\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:451\u001B[0m, in \u001B[0;36mFuture.result\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    448\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m    449\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[1;32m--> 451\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_condition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    453\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001B[0;32m    454\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 320\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    321\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    322\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "class QModel(Module):\n",
    "    def __init__(self, n_input_params : int, n_vars : int, num_edges_in_graph : int, n_layers : int,\n",
    "                 flattened_data_symbols : list, circuit : QuantumCircuit):\n",
    "        super(QModel, self).__init__()\n",
    "\n",
    "        self.encoding_layer = EquivariantLayer(num_input_params=n_input_params, n_vars=n_vars, n_edges=num_edges_in_graph,\n",
    "                                               circuit_depth=n_layers, params=flattened_data_symbols)\n",
    "\n",
    "        self.circuit = circuit\n",
    "\n",
    "    def forward(self, input_data, observables):\n",
    "        encoding_output = self.encoding_layer(input_data)\n",
    "\n",
    "        qnn = EstimatorQNN(\n",
    "            circuit=self.circuit,\n",
    "            input_params=self.circuit.parameters,\n",
    "            observables=observables\n",
    "        )\n",
    "        qnn = TorchConnector(qnn)\n",
    "        expectation_values = qnn(encoding_output)\n",
    "\n",
    "        return expectation_values\n",
    "    \n",
    "\n",
    "class QLearningTsp(QLearning):\n",
    "    def __init__(self,\n",
    "                 hyperparams : dict,\n",
    "                 path :str =BASE_PATH):\n",
    "\n",
    "        super(QLearningTsp, self).__init__(hyperparams, path)\n",
    "\n",
    "        self.fully_connected_qubits = list(combinations(list(range(self.n_vars)), 2))\n",
    "        self.is_multi_instance = hyperparams.get('is_multi_instance')\n",
    "        self.interaction = namedtuple(\n",
    "            typename='interaction', \n",
    "            field_names=('state', 'action', 'reward', 'next_state', 'done', 'partial_tour', 'edge_weights')\n",
    "        )\n",
    "        self.model = self.generate_eqc_model()\n",
    "\n",
    "        self.optimizer = Adam(self.model.parameters(), lr=self.learning_rate_in)\n",
    "\n",
    "        self.data_path = hyperparams.get('data_path')\n",
    "\n",
    "    def generate_eqc_model(self):\n",
    "        num_edges_in_graph = len(self.fully_connected_qubits)\n",
    "        n_input_params = self.n_vars + num_edges_in_graph\n",
    "\n",
    "        data_symbols = []\n",
    "        for layer in range(self.n_layers):\n",
    "            data = [Parameter(f'layer[{layer}]_v[{qubit}]') for qubit in range(self.n_vars)]\n",
    "            data += [[Parameter(f'layer[{layer}]_e[{ew}]') for ew in range(num_edges_in_graph)]]\n",
    "            data_symbols.append(data)\n",
    "\n",
    "        circuit = graph_encoding_circuit(self.fully_connected_qubits, self.n_vars, self.n_layers, data_symbols)\n",
    "\n",
    "        flattened_data_symbols = []\n",
    "        for layer in data_symbols:\n",
    "            for item in layer:\n",
    "                if type(item) == list:\n",
    "                    for symbol in item:\n",
    "                        flattened_data_symbols.append(str(symbol))\n",
    "                else:\n",
    "                    flattened_data_symbols.append(str(item))\n",
    "\n",
    "        model = QModel(n_input_params=n_input_params, \n",
    "                       n_vars=self.n_vars, \n",
    "                       num_edges_in_graph=num_edges_in_graph, \n",
    "                       n_layers=self.n_layers, \n",
    "                       flattened_data_symbols=flattened_data_symbols, \n",
    "                       circuit=circuit\n",
    "                       )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def get_observables(self, edge_weights: dict | list[dict], partial_tours:  list[int] | list[list[int]]) -> \\\n",
    "            (tuple[list[SparsePauliOp], list[int]] | list[tuple[list[SparsePauliOp], list[int]]]):\n",
    "        if not isinstance(edge_weights, list):\n",
    "            edge_weights = [edge_weights]\n",
    "\n",
    "        if not isinstance(partial_tours[0], list):\n",
    "            partial_tours = [partial_tours]\n",
    "\n",
    "        observables_batch = []\n",
    "        available_nodes_batch = []\n",
    "\n",
    "        for i, partial_tour in enumerate(partial_tours):\n",
    "            observables = []\n",
    "            available_nodes = []\n",
    "            last_edge = () if len(partial_tour) == 0 else partial_tour[-1] # TODO: Check the condition based on Skolik's code.\n",
    "            last_node = 0 if len(last_edge) == 0 else last_edge[1]\n",
    "\n",
    "            edge_weight_batch = edge_weights[i] if isinstance(edge_weights[i], list) else [edge_weights[i]]\n",
    "\n",
    "            for edge_weight in edge_weight_batch:\n",
    "                for edge, weight in edge_weight.items():\n",
    "                    if edge[0] == last_node or edge[1] == last_node:\n",
    "                        if edge[0] == last_node and len([tup for tup in partial_tour if tup[0] == edge[1]]) >= 1:\n",
    "                            continue\n",
    "                        elif edge[1] == last_node and len([tup for tup in partial_tour if tup[0] == edge[0]]) >= 1:\n",
    "                            continue\n",
    "\n",
    "                        if edge[0] == last_node:\n",
    "                            available_nodes.append(edge[1])\n",
    "                        else:\n",
    "                            available_nodes.append(edge[0])\n",
    "\n",
    "                        observable = SparsePauliOp.from_sparse_list(\n",
    "                            [(\"ZZ\", [edge[0], edge[1]], weight)],\n",
    "                            num_qubits=self.n_vars\n",
    "                        )\n",
    "                        observables.append(observable)\n",
    "\n",
    "            if observables == []:\n",
    "                observable = SparsePauliOp.from_sparse_list(\n",
    "                    [(\"I\", [0], 0)],\n",
    "                    num_qubits=self.n_vars\n",
    "                )\n",
    "                observables.append(observable)\n",
    "                available_nodes.append(0)\n",
    "\n",
    "            observables_batch.append(observables)\n",
    "            available_nodes_batch.append(available_nodes)\n",
    "\n",
    "        if len(partial_tours) == 1:\n",
    "            return observables_batch[0], available_nodes_batch[0]\n",
    "        else:\n",
    "            return observables_batch, available_nodes_batch\n",
    "\n",
    "    def get_action(self, state_list : list[float], available_nodes : list,\n",
    "                   partial_tour : list[int], edge_weights : dict) -> int:\n",
    "\n",
    "        if np.random.uniform() < self.epsilon:\n",
    "            action = random.choice(available_nodes)\n",
    "        else:\n",
    "            state_tensor = torch.tensor(state_list).unsqueeze(0)\n",
    "\n",
    "            observables, available_nodes = self.get_observables(\n",
    "                edge_weights=edge_weights,\n",
    "                partial_tours=[partial_tour]\n",
    "            )\n",
    "            expectations = self.model(state_tensor, observables)\n",
    "            action = available_nodes[torch.argmax(torch.tensor(expectations)).item()]\n",
    "\n",
    "        return action\n",
    "    \n",
    "    def q_vals_from_expectations(self, partial_tours, edge_weights, expectations):\n",
    "        expectations = expectations.detach().numpy()\n",
    "        indexed_expectations = []\n",
    "        for exps in expectations:\n",
    "            batch_ix_exp = {}\n",
    "            for edge, exp_val in zip(self.fully_connected_qubits, exps):\n",
    "                batch_ix_exp[edge] = exp_val\n",
    "            indexed_expectations.append(batch_ix_exp)\n",
    "\n",
    "        batch_q_vals = []\n",
    "        for tour_ix, partial_tour in enumerate(partial_tours):\n",
    "            q_vals = []\n",
    "            for i in range(self.n_vars):\n",
    "                node_in_tour = False\n",
    "                for edge in partial_tour:\n",
    "                    if i in edge:\n",
    "                        node_in_tour = True\n",
    "\n",
    "                if not node_in_tour:\n",
    "                    next_edge = None\n",
    "                    if partial_tour:\n",
    "                        next_edge = (partial_tour[-1][1], i)\n",
    "                    else:\n",
    "                        if i > 0:\n",
    "                            next_edge = (0, i)\n",
    "\n",
    "                    if next_edge is not None:\n",
    "                        try:\n",
    "                            q_val = edge_weights[tour_ix][next_edge] * indexed_expectations[tour_ix][next_edge]\n",
    "                        except KeyError:\n",
    "                            q_val = edge_weights[tour_ix][\n",
    "                                (next_edge[1], next_edge[0])] * indexed_expectations[tour_ix][\n",
    "                                        (next_edge[1], next_edge[0])]\n",
    "                    else:\n",
    "                        q_val = -10000\n",
    "                else:\n",
    "                    q_val = -10000\n",
    "                q_vals.append(q_val)\n",
    "\n",
    "            batch_q_vals.append(q_vals)\n",
    "\n",
    "        return np.asarray(batch_q_vals)\n",
    "\n",
    "    def train_step(self):\n",
    "        training_batch = random.choices(self.memory, k=self.batch_size)\n",
    "        training_batch = self.interaction(*zip(*training_batch))\n",
    "\n",
    "        states = [x for x in training_batch.state]\n",
    "        rewards = np.asarray([x for x in training_batch.reward], dtype=np.float32)\n",
    "        next_states = [x for x in training_batch.next_state]\n",
    "        done = np.asarray([x for x in training_batch.done])\n",
    "        partial_tours = [x for x in training_batch.partial_tour]\n",
    "        edge_weights = [x for x in training_batch.edge_weights]\n",
    "\n",
    "        states = torch.tensor(states)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32)\n",
    "        next_states = torch.tensor(next_states)\n",
    "        done = torch.tensor(done, dtype=torch.float64)\n",
    "        \n",
    "        readout_op = self.get_readout_op()\n",
    "        exp_values_future = self.model(next_states, readout_op)\n",
    "        future_rewards = torch.tensor(self.q_vals_from_expectations(\n",
    "            partial_tours, edge_weights, exp_values_future), dtype=torch.float32)\n",
    "\n",
    "        target_q_values = rewards + (\n",
    "                self.gamma * torch.max(future_rewards) * (1.0 - done)\n",
    "        )\n",
    "\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        exp_val_masks = get_masks_for_actions(edge_weights, partial_tours)\n",
    "        exp_values = self.model(states, readout_op)\n",
    "        q_values_masked = torch.sum(exp_values.detach() * exp_val_masks, dim=1)\n",
    "        loss = self.loss_fun(target_q_values, q_values_masked)\n",
    "\n",
    "        # TODO: Optimize gradients\n",
    "\n",
    "        pass\n",
    "    \n",
    "    def get_readout_op(self):\n",
    "        observables = []\n",
    "        for edge in self.fully_connected_qubits:\n",
    "            observable = SparsePauliOp.from_sparse_list(\n",
    "                            [(\"ZZ\", [edge[0], edge[1]], 1)],\n",
    "                            num_qubits=self.n_vars\n",
    "                        )\n",
    "            observables.append(observable)\n",
    "        return observables\n",
    "\n",
    "    def perform_episodes(self, num_instances : int) -> None:\n",
    "        self.meta['num_instances'] = num_instances\n",
    "        self.meta['best_tour_length'] = 100000\n",
    "        self.meta['best_tour'] = []\n",
    "        self.meta['best_tour_ix'] = 0\n",
    "        self.meta['env_solved'] = False\n",
    "\n",
    "        with open(self.data_path, 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "\n",
    "        if self.is_multi_instance:\n",
    "            x_train = data['x_train'][:num_instances]\n",
    "            y_train = data['y_train'][:num_instances]\n",
    "        else:\n",
    "            x_train = data['x_train']\n",
    "            y_train = data['y_train']\n",
    "\n",
    "        tour_length_history = []\n",
    "        optimal_tour_length_history = []\n",
    "        ratio_history = []\n",
    "        running_avgs = []\n",
    "        running_avg = 0\n",
    "\n",
    "        for episode in range(self.episodes):\n",
    "            instance_number = random.randint(0, num_instances - 1)\n",
    "            tsp_graph_nodes = x_train[instance_number]\n",
    "            optimal_tour_length = compute_tour_length(\n",
    "                tsp_graph_nodes, [int(x - 1) for x in y_train[instance_number][:-1]])\n",
    "            node_to_qubit_map = {}\n",
    "            for i, node in enumerate(tsp_graph_nodes):\n",
    "                node_to_qubit_map[node] = i\n",
    "\n",
    "            fully_connected_edges = []\n",
    "            edge_weights = {}\n",
    "            edge_weights_ix = {}\n",
    "            for edge in self.fully_connected_qubits:\n",
    "                fully_connected_edges.append((tsp_graph_nodes[edge[0]], tsp_graph_nodes[edge[1]]))\n",
    "                edge_distance = np.linalg.norm(\n",
    "                    np.asarray(tsp_graph_nodes[edge[0]]) - np.asarray(tsp_graph_nodes[edge[1]]))\n",
    "                edge_weights[(tsp_graph_nodes[edge[0]], tsp_graph_nodes[edge[1]])] = edge_distance\n",
    "                edge_weights_ix[edge] = edge_distance\n",
    "\n",
    "            tour = [0]  # Without loss of generality we always start at city 0\n",
    "            tour_edges = []\n",
    "            step_rewards = []\n",
    "            available_nodes = list(range(1, self.n_vars))\n",
    "\n",
    "            for i in range(self.n_vars):\n",
    "                prev_tour = copy.deepcopy(tour)\n",
    "                state_list = graph_to_list(\n",
    "                    tsp_graph_nodes, fully_connected_edges, edge_weights,\n",
    "                    available_nodes, node_to_qubit_map)\n",
    "                \n",
    "                # TODO: Check Skolik's code why can len(tour_edges) become zero, and how it handles it.\n",
    "                next_node = self.get_action(state_list, available_nodes, tour_edges, edge_weights_ix)\n",
    "                tour_edges.append((tour[-1], next_node))\n",
    "                new_tour_edges = copy.deepcopy(tour_edges)\n",
    "                tour.append(next_node)\n",
    "\n",
    "                remove_node_ix = available_nodes.index(next_node)\n",
    "                del available_nodes[remove_node_ix]\n",
    "\n",
    "                if len(tour) > 1:\n",
    "                    reward = compute_reward(tsp_graph_nodes, prev_tour, tour)\n",
    "                    step_rewards.append(reward)\n",
    "\n",
    "                    done = 0 if len(available_nodes) > 1 else 1\n",
    "                    transition = (state_list, next_node, reward, graph_to_list(\n",
    "                        tsp_graph_nodes, fully_connected_edges, edge_weights,\n",
    "                        available_nodes, node_to_qubit_map), done, new_tour_edges, edge_weights_ix)\n",
    "                    self.memory.append(transition)\n",
    "\n",
    "                if len(available_nodes) == 1:\n",
    "                    prev_tour = copy.deepcopy(tour)\n",
    "\n",
    "                    tour_edges.append((tour[-1], available_nodes[0]))\n",
    "                    tour_edges.append((available_nodes[0], tour[0]))\n",
    "                    new_tour_edges = copy.deepcopy(tour_edges)\n",
    "\n",
    "                    tour.append(available_nodes[0])\n",
    "                    tour.append(tour[0])\n",
    "\n",
    "                    reward = compute_reward(tsp_graph_nodes, prev_tour, tour)\n",
    "                    step_rewards.append(reward)\n",
    "\n",
    "                    transition = (state_list, next_node, reward, graph_to_list(\n",
    "                        tsp_graph_nodes, fully_connected_edges, edge_weights,\n",
    "                        available_nodes, node_to_qubit_map), 1, new_tour_edges, edge_weights_ix)\n",
    "                    self.memory.append(transition)\n",
    "                    break\n",
    "\n",
    "            tour_length = compute_tour_length(tsp_graph_nodes, tour)\n",
    "            tour_length_history.append(tour_length)\n",
    "            optimal_tour_length_history.append(optimal_tour_length)\n",
    "\n",
    "            if tour_length < self.meta.get('best_tour_length'):\n",
    "                self.meta['best_tour_length'] = tour_length\n",
    "                self.meta['best_tour'] = tour\n",
    "                self.meta['best_tour_ix'] = instance_number\n",
    "\n",
    "            if len(self.memory) >= self.batch_size:\n",
    "                if episode % self.update_after == 0:\n",
    "                    loss = self.train_step()\n",
    "                    print(\n",
    "                        f\"Episode {episode}, loss {loss}, running avg {running_avg}, epsilon {self.epsilon}\")\n",
    "                    print(f\"\\tFinal tour: {tour}\")\n",
    "                else:\n",
    "                    print(\n",
    "                            f\"Episode {episode}, running avg {running_avg}, epsilon {self.epsilon}\")\n",
    "                    print(f\"\\tFinal tour: {tour}\")\n",
    "\n",
    "                # TODO: Update model weights based on loss.\n",
    "\n",
    "            if self.epsilon_schedule == 'fast':\n",
    "                self.epsilon = max(self.epsilon_min, self.epsilon_decay * self.epsilon)\n",
    "\n",
    "            ratio_history.append(tour_length_history[-1] / optimal_tour_length)\n",
    "\n",
    "            if len(ratio_history) >= 100:\n",
    "                running_avg = np.mean(ratio_history[-100:])\n",
    "            else:\n",
    "                running_avg = np.mean(ratio_history)\n",
    "\n",
    "            running_avgs.append(running_avg)\n",
    "\n",
    "            if len(ratio_history) >= 100 and running_avg <= 1.05:\n",
    "                print(f\"Environment solved in {episode+1} episodes!\")\n",
    "                self.meta['env_solved'] = True\n",
    "                break\n",
    "\n",
    "        # This is just for visualization purposes.\n",
    "        plt.plot(running_avgs)\n",
    "        plt.ylabel(\"Ratio to optimal tour length\")\n",
    "        plt.xlabel(\"Episode\")\n",
    "        plt.title(\"Running average over past 100 episodes\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "for i in range(hyperparams.get('repetitions', 1)):\n",
    "    tsp_multi = QLearningTsp(\n",
    "        hyperparams=hyperparams,\n",
    "        path='/save_path/',\n",
    "    )\n",
    "\n",
    "    tsp_multi.perform_episodes(\n",
    "        num_instances=hyperparams.get('num_instances')\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:13:07.638946300Z",
     "start_time": "2023-11-30T10:09:05.103153100Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
